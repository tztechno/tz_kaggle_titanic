{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:21.460765Z",
     "iopub.status.busy": "2020-10-27T04:09:21.459975Z",
     "iopub.status.idle": "2020-10-27T04:09:22.664558Z",
     "shell.execute_reply": "2020-10-27T04:09:22.663797Z"
    },
    "papermill": {
     "duration": 1.248979,
     "end_time": "2020-10-27T04:09:22.664691",
     "exception": false,
     "start_time": "2020-10-27T04:09:21.415712",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:22.742087Z",
     "iopub.status.busy": "2020-10-27T04:09:22.741305Z",
     "iopub.status.idle": "2020-10-27T04:09:22.762485Z",
     "shell.execute_reply": "2020-10-27T04:09:22.761657Z"
    },
    "papermill": {
     "duration": 0.063105,
     "end_time": "2020-10-27T04:09:22.762615",
     "exception": false,
     "start_time": "2020-10-27T04:09:22.699510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/titanic/train.csv')\n",
    "data_train = np.array(df_train)\n",
    "df_test = pd.read_csv('../input/titanic/test.csv')\n",
    "data_test = np.array(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:22.840890Z",
     "iopub.status.busy": "2020-10-27T04:09:22.839835Z",
     "iopub.status.idle": "2020-10-27T04:09:22.844236Z",
     "shell.execute_reply": "2020-10-27T04:09:22.844802Z"
    },
    "papermill": {
     "duration": 0.047549,
     "end_time": "2020-10-27T04:09:22.844986",
     "exception": false,
     "start_time": "2020-10-27T04:09:22.797437",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 3, ..., 7.25, nan, 'S'],\n",
       "       [2, 1, 1, ..., 71.2833, 'C85', 'C'],\n",
       "       [3, 1, 3, ..., 7.925, nan, 'S'],\n",
       "       ...,\n",
       "       [889, 0, 3, ..., 23.45, nan, 'S'],\n",
       "       [890, 1, 1, ..., 30.0, 'C148', 'C'],\n",
       "       [891, 0, 3, ..., 7.75, nan, 'Q']], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:22.922103Z",
     "iopub.status.busy": "2020-10-27T04:09:22.921132Z",
     "iopub.status.idle": "2020-10-27T04:09:22.925466Z",
     "shell.execute_reply": "2020-10-27T04:09:22.926047Z"
    },
    "papermill": {
     "duration": 0.045811,
     "end_time": "2020-10-27T04:09:22.926226",
     "exception": false,
     "start_time": "2020-10-27T04:09:22.880415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "891"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.004631Z",
     "iopub.status.busy": "2020-10-27T04:09:23.003504Z",
     "iopub.status.idle": "2020-10-27T04:09:23.008361Z",
     "shell.execute_reply": "2020-10-27T04:09:23.007594Z"
    },
    "papermill": {
     "duration": 0.046471,
     "end_time": "2020-10-27T04:09:23.008504",
     "exception": false,
     "start_time": "2020-10-27T04:09:22.962033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.091007Z",
     "iopub.status.busy": "2020-10-27T04:09:23.090166Z",
     "iopub.status.idle": "2020-10-27T04:09:23.100228Z",
     "shell.execute_reply": "2020-10-27T04:09:23.099470Z"
    },
    "papermill": {
     "duration": 0.055819,
     "end_time": "2020-10-27T04:09:23.100355",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.044536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = []\n",
    "for i in range(0, len(data_train)):\n",
    "    tg.append(data_train[i][1])\n",
    "target = np.array(tg)\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.181153Z",
     "iopub.status.busy": "2020-10-27T04:09:23.180086Z",
     "iopub.status.idle": "2020-10-27T04:09:23.513888Z",
     "shell.execute_reply": "2020-10-27T04:09:23.513092Z"
    },
    "papermill": {
     "duration": 0.37675,
     "end_time": "2020-10-27T04:09:23.514040",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.137290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target2=pd.DataFrame(target)\n",
    "target2.to_csv('target4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.595727Z",
     "iopub.status.busy": "2020-10-27T04:09:23.594843Z",
     "iopub.status.idle": "2020-10-27T04:09:23.599518Z",
     "shell.execute_reply": "2020-10-27T04:09:23.598788Z"
    },
    "papermill": {
     "duration": 0.046893,
     "end_time": "2020-10-27T04:09:23.599639",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.552746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.679668Z",
     "iopub.status.busy": "2020-10-27T04:09:23.678587Z",
     "iopub.status.idle": "2020-10-27T04:09:23.683382Z",
     "shell.execute_reply": "2020-10-27T04:09:23.682691Z"
    },
    "papermill": {
     "duration": 0.047048,
     "end_time": "2020-10-27T04:09:23.683520",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.636472",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.770270Z",
     "iopub.status.busy": "2020-10-27T04:09:23.767736Z",
     "iopub.status.idle": "2020-10-27T04:09:23.774481Z",
     "shell.execute_reply": "2020-10-27T04:09:23.773907Z"
    },
    "papermill": {
     "duration": 0.053231,
     "end_time": "2020-10-27T04:09:23.774603",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.721372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 'Braund, Mr. Owen Harris', 'male', ..., 7.25, nan, 'S'],\n",
       "       [1, 'Cumings, Mrs. John Bradley (Florence Briggs Thayer)',\n",
       "        'female', ..., 71.2833, 'C85', 'C'],\n",
       "       [3, 'Heikkinen, Miss. Laina', 'female', ..., 7.925, nan, 'S'],\n",
       "       ...,\n",
       "       [3, 'Saether, Mr. Simon Sivertsen', 'male', ..., 7.25, nan, 'S'],\n",
       "       [3, 'Ware, Mr. Frederick', 'male', ..., 8.05, nan, 'S'],\n",
       "       [3, 'Peter, Master. Michael J', 'male', ..., 22.3583, nan, 'C']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td=[]\n",
    "for i in range(0, len(data_train)):\n",
    "    td.append(data_train[i][2:])\n",
    "for i in range(0, len(data_test)):\n",
    "    td.append(data_test[i][1:])\n",
    "traintestdata = np.array(td)\n",
    "traintestdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.858955Z",
     "iopub.status.busy": "2020-10-27T04:09:23.858175Z",
     "iopub.status.idle": "2020-10-27T04:09:23.862607Z",
     "shell.execute_reply": "2020-10-27T04:09:23.861862Z"
    },
    "papermill": {
     "duration": 0.050648,
     "end_time": "2020-10-27T04:09:23.862728",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.812080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "    td.append(traintestdata[i][0])\n",
    "max(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:23.950833Z",
     "iopub.status.busy": "2020-10-27T04:09:23.950054Z",
     "iopub.status.idle": "2020-10-27T04:09:23.954578Z",
     "shell.execute_reply": "2020-10-27T04:09:23.953841Z"
    },
    "papermill": {
     "duration": 0.053932,
     "end_time": "2020-10-27T04:09:23.954707",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.900775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pcalss\n",
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "    td.append((traintestdata[i][0]-1)/2)\n",
    "traintestdata_Pclass = np.array(td)\n",
    "traintestdata_Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.043583Z",
     "iopub.status.busy": "2020-10-27T04:09:24.042637Z",
     "iopub.status.idle": "2020-10-27T04:09:24.047502Z",
     "shell.execute_reply": "2020-10-27T04:09:24.046798Z"
    },
    "papermill": {
     "duration": 0.053777,
     "end_time": "2020-10-27T04:09:24.047632",
     "exception": false,
     "start_time": "2020-10-27T04:09:23.993855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sex\n",
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "    if traintestdata[i][2] == 'male':\n",
    "        td.append(0)\n",
    "    else:\n",
    "        td.append(1)   \n",
    "traintestdata_sex = np.array(td)\n",
    "traintestdata_sex\n",
    "#male0,female1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.137036Z",
     "iopub.status.busy": "2020-10-27T04:09:24.135597Z",
     "iopub.status.idle": "2020-10-27T04:09:24.141331Z",
     "shell.execute_reply": "2020-10-27T04:09:24.140573Z"
    },
    "papermill": {
     "duration": 0.054682,
     "end_time": "2020-10-27T04:09:24.141459",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.086777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.704102368220013"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "    if str(traintestdata[i][3]) == 'nan':\n",
    "        td.append(29)\n",
    "    else:\n",
    "        td.append(traintestdata[i][3])\n",
    "        \n",
    "np.mean(td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.234491Z",
     "iopub.status.busy": "2020-10-27T04:09:24.233456Z",
     "iopub.status.idle": "2020-10-27T04:09:24.238630Z",
     "shell.execute_reply": "2020-10-27T04:09:24.237835Z"
    },
    "papermill": {
     "duration": 0.057937,
     "end_time": "2020-10-27T04:09:24.238756",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.180819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.275  , 0.475  , 0.325  , ..., 0.48125, 0.3625 , 0.3625 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#age\n",
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "    if str(traintestdata[i][3]) == 'nan':\n",
    "        td.append(29/80)\n",
    "    else:\n",
    "        td.append(traintestdata[i][3]/80)\n",
    "\n",
    "traintestdata_age = np.array(td)\n",
    "traintestdata_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.330314Z",
     "iopub.status.busy": "2020-10-27T04:09:24.329298Z",
     "iopub.status.idle": "2020-10-27T04:09:24.334366Z",
     "shell.execute_reply": "2020-10-27T04:09:24.333611Z"
    },
    "papermill": {
     "duration": 0.055909,
     "end_time": "2020-10-27T04:09:24.334502",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.278593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18181818, 0.18181818, 0.09090909, ..., 0.09090909, 0.09090909,\n",
       "       0.27272727])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#family\n",
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "        td.append((1+traintestdata[i][4]+traintestdata[i][5])/11)  \n",
    "traintestdata_family = np.array(td)\n",
    "traintestdata_family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.428748Z",
     "iopub.status.busy": "2020-10-27T04:09:24.427771Z",
     "iopub.status.idle": "2020-10-27T04:09:24.432644Z",
     "shell.execute_reply": "2020-10-27T04:09:24.431910Z"
    },
    "papermill": {
     "duration": 0.057794,
     "end_time": "2020-10-27T04:09:24.432766",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.374972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01415106, 0.13913574, 0.01546857, ..., 0.01415106, 0.01571255,\n",
       "       0.0436405 ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fare\n",
    "td=[]\n",
    "for i in range(0, len(traintestdata)): \n",
    "    if str(traintestdata[i][7]) == 'nan':\n",
    "        td.append(0.065)           \n",
    "    else:\n",
    "        td.append(traintestdata[i][7]/512.3292)     \n",
    "        \n",
    "traintestdata_fare = np.array(td)\n",
    "traintestdata_fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.527615Z",
     "iopub.status.busy": "2020-10-27T04:09:24.526578Z",
     "iopub.status.idle": "2020-10-27T04:09:24.531433Z",
     "shell.execute_reply": "2020-10-27T04:09:24.530692Z"
    },
    "papermill": {
     "duration": 0.058161,
     "end_time": "2020-10-27T04:09:24.531557",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.473396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.66666667, 0.        , ..., 0.        , 0.        ,\n",
       "       0.66666667])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#embarked\n",
    "td=[]\n",
    "for i in range(0, len(traintestdata)):\n",
    "    if traintestdata[i][9]=='S':\n",
    "        td.append(0/3)          \n",
    "    elif traintestdata[i][9]=='Q':\n",
    "        td.append(1/3)          \n",
    "    elif traintestdata[i][9]=='C':\n",
    "        td.append(2/3)          \n",
    "    else:\n",
    "        td.append(3/3)  \n",
    "        \n",
    "traintestdata_embarked = np.array(td)\n",
    "traintestdata_embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.654174Z",
     "iopub.status.busy": "2020-10-27T04:09:24.653139Z",
     "iopub.status.idle": "2020-10-27T04:09:24.659442Z",
     "shell.execute_reply": "2020-10-27T04:09:24.658614Z"
    },
    "papermill": {
     "duration": 0.076706,
     "end_time": "2020-10-27T04:09:24.659615",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.582909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.275     , 0.18181818, 0.01415106,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.475     , 0.18181818, 0.13913574,\n",
       "        0.66666667],\n",
       "       [1.        , 1.        , 0.325     , 0.09090909, 0.01546857,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [1.        , 0.        , 0.48125   , 0.09090909, 0.01415106,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.3625    , 0.09090909, 0.01571255,\n",
       "        0.        ],\n",
       "       [1.        , 0.        , 0.3625    , 0.27272727, 0.0436405 ,\n",
       "        0.66666667]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traintestdata2=[]\n",
    "\n",
    "traintestdata２.append(traintestdata_Pclass)\n",
    "traintestdata２.append(traintestdata_sex)\n",
    "traintestdata２.append(traintestdata_age)\n",
    "traintestdata２.append(traintestdata_family)\n",
    "traintestdata２.append(traintestdata_fare)\n",
    "traintestdata２.append(traintestdata_embarked)\n",
    "\n",
    "traintestdata3=np.transpose(traintestdata2)\n",
    "traintestdata3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.757167Z",
     "iopub.status.busy": "2020-10-27T04:09:24.756127Z",
     "iopub.status.idle": "2020-10-27T04:09:24.777694Z",
     "shell.execute_reply": "2020-10-27T04:09:24.776951Z"
    },
    "papermill": {
     "duration": 0.069436,
     "end_time": "2020-10-27T04:09:24.777817",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.708381",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "traintestdata4=pd.DataFrame(traintestdata3)\n",
    "traintestdata4.to_csv('traintestdata4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:24.868877Z",
     "iopub.status.busy": "2020-10-27T04:09:24.867952Z",
     "iopub.status.idle": "2020-10-27T04:09:30.877831Z",
     "shell.execute_reply": "2020-10-27T04:09:30.877051Z"
    },
    "papermill": {
     "duration": 6.058345,
     "end_time": "2020-10-27T04:09:30.877973",
     "exception": false,
     "start_time": "2020-10-27T04:09:24.819628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "\n",
    "from keras.models import Sequential \n",
    "from keras.layers.core import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:30.974081Z",
     "iopub.status.busy": "2020-10-27T04:09:30.973034Z",
     "iopub.status.idle": "2020-10-27T04:09:30.985583Z",
     "shell.execute_reply": "2020-10-27T04:09:30.984871Z"
    },
    "papermill": {
     "duration": 0.066227,
     "end_time": "2020-10-27T04:09:30.985709",
     "exception": false,
     "start_time": "2020-10-27T04:09:30.919482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "print(__doc__)\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('traintestdata4.csv')\n",
    "data=np.array(df)\n",
    "\n",
    "dt=pd.read_csv('target4.csv')\n",
    "target=np.array(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:31.076287Z",
     "iopub.status.busy": "2020-10-27T04:09:31.075527Z",
     "iopub.status.idle": "2020-10-27T04:09:31.079058Z",
     "shell.execute_reply": "2020-10-27T04:09:31.078309Z"
    },
    "papermill": {
     "duration": 0.051721,
     "end_time": "2020-10-27T04:09:31.079181",
     "exception": false,
     "start_time": "2020-10-27T04:09:31.027460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = np.array(data[0:891])\n",
    "y = np.array(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:31.171511Z",
     "iopub.status.busy": "2020-10-27T04:09:31.170682Z",
     "iopub.status.idle": "2020-10-27T04:09:31.295034Z",
     "shell.execute_reply": "2020-10-27T04:09:31.294345Z"
    },
    "papermill": {
     "duration": 0.173807,
     "end_time": "2020-10-27T04:09:31.295167",
     "exception": false,
     "start_time": "2020-10-27T04:09:31.121360",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "ss = ShuffleSplit(n_splits=1,\n",
    "                  train_size=0.9,\n",
    "                  test_size =0.1,\n",
    "                  random_state=0)\n",
    "\n",
    "train_index, test_index = next(ss.split(X)) \n",
    "list(train_index), list(test_index) \n",
    "\n",
    "X_train, X_test = X[train_index], X[test_index]\n",
    "Y_train, Y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:31.386464Z",
     "iopub.status.busy": "2020-10-27T04:09:31.385685Z",
     "iopub.status.idle": "2020-10-27T04:09:31.396794Z",
     "shell.execute_reply": "2020-10-27T04:09:31.396058Z"
    },
    "papermill": {
     "duration": 0.059761,
     "end_time": "2020-10-27T04:09:31.396933",
     "exception": false,
     "start_time": "2020-10-27T04:09:31.337172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NB_EPOCH = 600\n",
    "VERBOSE = 1\n",
    "OPTIMIZER = SGD() \n",
    "BATCH_SIZE = 32\n",
    "NB_CLASSES = 2\n",
    "\n",
    "N_HIDDEN0 = 512\n",
    "N_HIDDEN1 = 256\n",
    "N_HIDDEN2 = 128\n",
    "N_HIDDEN3 = 128\n",
    "N_HIDDEN4 = 64\n",
    "N_HIDDEN5 = 64\n",
    "\n",
    "DROPOUT = 0.5\n",
    "VALIDATION_SPLIT = 0.5\n",
    "RESHAPED = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:31.495040Z",
     "iopub.status.busy": "2020-10-27T04:09:31.494231Z",
     "iopub.status.idle": "2020-10-27T04:09:31.744495Z",
     "shell.execute_reply": "2020-10-27T04:09:31.743414Z"
    },
    "papermill": {
     "duration": 0.305942,
     "end_time": "2020-10-27T04:09:31.744673",
     "exception": false,
     "start_time": "2020-10-27T04:09:31.438731",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               3584      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 196,866\n",
      "Trainable params: 196,866\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add (Dense(N_HIDDEN0, input_shape = (RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "\n",
    "model.add (Dense(N_HIDDEN1))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add (Dense(N_HIDDEN2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add (Dense(N_HIDDEN3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add (Dense(N_HIDDEN4))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "model.add (Dense(N_HIDDEN5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(DROPOUT))\n",
    "\n",
    "\n",
    "model.add (Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:31.843094Z",
     "iopub.status.busy": "2020-10-27T04:09:31.840083Z",
     "iopub.status.idle": "2020-10-27T04:09:31.849330Z",
     "shell.execute_reply": "2020-10-27T04:09:31.849869Z"
    },
    "papermill": {
     "duration": 0.061785,
     "end_time": "2020-10-27T04:09:31.850047",
     "exception": false,
     "start_time": "2020-10-27T04:09:31.788262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss = 'sparse_categorical_crossentropy',\n",
    "             optimizer = OPTIMIZER,\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:09:31.941672Z",
     "iopub.status.busy": "2020-10-27T04:09:31.940910Z",
     "iopub.status.idle": "2020-10-27T04:10:35.614153Z",
     "shell.execute_reply": "2020-10-27T04:10:35.613497Z"
    },
    "papermill": {
     "duration": 63.721919,
     "end_time": "2020-10-27T04:10:35.614295",
     "exception": false,
     "start_time": "2020-10-27T04:09:31.892376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.6857 - accuracy: 0.5943 - val_loss: 0.6844 - val_accuracy: 0.5667\n",
      "Epoch 2/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6799 - accuracy: 0.5880 - val_loss: 0.6841 - val_accuracy: 0.5667\n",
      "Epoch 3/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6741 - accuracy: 0.6167 - val_loss: 0.6820 - val_accuracy: 0.5667\n",
      "Epoch 4/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6650 - accuracy: 0.6292 - val_loss: 0.6801 - val_accuracy: 0.5667\n",
      "Epoch 5/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6729 - accuracy: 0.6180 - val_loss: 0.6790 - val_accuracy: 0.5667\n",
      "Epoch 6/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.6230 - val_loss: 0.6780 - val_accuracy: 0.5667\n",
      "Epoch 7/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6704 - accuracy: 0.6217 - val_loss: 0.6767 - val_accuracy: 0.5667\n",
      "Epoch 8/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.6716 - accuracy: 0.6230 - val_loss: 0.6754 - val_accuracy: 0.5667\n",
      "Epoch 9/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6669 - accuracy: 0.6142 - val_loss: 0.6752 - val_accuracy: 0.5667\n",
      "Epoch 10/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6668 - accuracy: 0.6205 - val_loss: 0.6750 - val_accuracy: 0.5667\n",
      "Epoch 11/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6604 - accuracy: 0.6167 - val_loss: 0.6728 - val_accuracy: 0.5667\n",
      "Epoch 12/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6636 - accuracy: 0.6167 - val_loss: 0.6721 - val_accuracy: 0.5667\n",
      "Epoch 13/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.6217 - val_loss: 0.6705 - val_accuracy: 0.5667\n",
      "Epoch 14/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6675 - accuracy: 0.6180 - val_loss: 0.6697 - val_accuracy: 0.5667\n",
      "Epoch 15/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.6205 - val_loss: 0.6683 - val_accuracy: 0.5667\n",
      "Epoch 16/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6609 - accuracy: 0.6180 - val_loss: 0.6668 - val_accuracy: 0.5667\n",
      "Epoch 17/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.6217 - val_loss: 0.6644 - val_accuracy: 0.5667\n",
      "Epoch 18/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6553 - accuracy: 0.6217 - val_loss: 0.6613 - val_accuracy: 0.5667\n",
      "Epoch 19/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6590 - accuracy: 0.6180 - val_loss: 0.6596 - val_accuracy: 0.5667\n",
      "Epoch 20/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.6230 - val_loss: 0.6567 - val_accuracy: 0.5667\n",
      "Epoch 21/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6614 - accuracy: 0.6192 - val_loss: 0.6542 - val_accuracy: 0.5667\n",
      "Epoch 22/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.6205 - val_loss: 0.6532 - val_accuracy: 0.5667\n",
      "Epoch 23/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6499 - accuracy: 0.6192 - val_loss: 0.6498 - val_accuracy: 0.5667\n",
      "Epoch 24/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.6205 - val_loss: 0.6469 - val_accuracy: 0.5667\n",
      "Epoch 25/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6393 - accuracy: 0.6230 - val_loss: 0.6444 - val_accuracy: 0.5667\n",
      "Epoch 26/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.6205 - val_loss: 0.6419 - val_accuracy: 0.5667\n",
      "Epoch 27/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.6192 - val_loss: 0.6381 - val_accuracy: 0.5667\n",
      "Epoch 28/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6230 - val_loss: 0.6308 - val_accuracy: 0.5667\n",
      "Epoch 29/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6299 - accuracy: 0.6217 - val_loss: 0.6243 - val_accuracy: 0.5667\n",
      "Epoch 30/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6286 - accuracy: 0.6217 - val_loss: 0.6180 - val_accuracy: 0.5667\n",
      "Epoch 31/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.6180 - val_loss: 0.6124 - val_accuracy: 0.5667\n",
      "Epoch 32/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.6155 - val_loss: 0.6160 - val_accuracy: 0.5667\n",
      "Epoch 33/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.6230 - val_loss: 0.6100 - val_accuracy: 0.5667\n",
      "Epoch 34/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6130 - accuracy: 0.6192 - val_loss: 0.6056 - val_accuracy: 0.5667\n",
      "Epoch 35/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6114 - accuracy: 0.6192 - val_loss: 0.5948 - val_accuracy: 0.5667\n",
      "Epoch 36/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6079 - accuracy: 0.6230 - val_loss: 0.5886 - val_accuracy: 0.5667\n",
      "Epoch 37/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5990 - accuracy: 0.6280 - val_loss: 0.6006 - val_accuracy: 0.7889\n",
      "Epoch 38/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6011 - accuracy: 0.6404 - val_loss: 0.5818 - val_accuracy: 0.8000\n",
      "Epoch 39/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6068 - accuracy: 0.6367 - val_loss: 0.5705 - val_accuracy: 0.8000\n",
      "Epoch 40/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5995 - accuracy: 0.6367 - val_loss: 0.5649 - val_accuracy: 0.8000\n",
      "Epoch 41/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5968 - accuracy: 0.6342 - val_loss: 0.5585 - val_accuracy: 0.8000\n",
      "Epoch 42/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5903 - accuracy: 0.6554 - val_loss: 0.5535 - val_accuracy: 0.8000\n",
      "Epoch 43/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.6026 - accuracy: 0.6629 - val_loss: 0.5512 - val_accuracy: 0.8000\n",
      "Epoch 44/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5763 - accuracy: 0.6979 - val_loss: 0.5451 - val_accuracy: 0.7778\n",
      "Epoch 45/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5804 - accuracy: 0.7154 - val_loss: 0.5414 - val_accuracy: 0.8000\n",
      "Epoch 46/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7041 - val_loss: 0.5417 - val_accuracy: 0.7889\n",
      "Epoch 47/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5816 - accuracy: 0.7416 - val_loss: 0.5835 - val_accuracy: 0.8222\n",
      "Epoch 48/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5787 - accuracy: 0.7578 - val_loss: 0.5508 - val_accuracy: 0.7778\n",
      "Epoch 49/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5823 - accuracy: 0.7466 - val_loss: 0.5397 - val_accuracy: 0.7889\n",
      "Epoch 50/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5772 - accuracy: 0.7653 - val_loss: 0.5392 - val_accuracy: 0.8000\n",
      "Epoch 51/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5711 - accuracy: 0.7591 - val_loss: 0.5295 - val_accuracy: 0.7778\n",
      "Epoch 52/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5653 - accuracy: 0.7578 - val_loss: 0.5244 - val_accuracy: 0.7778\n",
      "Epoch 53/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7603 - val_loss: 0.5246 - val_accuracy: 0.7778\n",
      "Epoch 54/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5709 - accuracy: 0.7665 - val_loss: 0.5212 - val_accuracy: 0.7778\n",
      "Epoch 55/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5480 - accuracy: 0.7840 - val_loss: 0.5220 - val_accuracy: 0.8000\n",
      "Epoch 56/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5608 - accuracy: 0.7828 - val_loss: 0.5080 - val_accuracy: 0.7778\n",
      "Epoch 57/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5415 - accuracy: 0.7878 - val_loss: 0.5069 - val_accuracy: 0.8000\n",
      "Epoch 58/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.7853 - val_loss: 0.5082 - val_accuracy: 0.8000\n",
      "Epoch 59/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5641 - accuracy: 0.7628 - val_loss: 0.5008 - val_accuracy: 0.8000\n",
      "Epoch 60/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5670 - accuracy: 0.7678 - val_loss: 0.5027 - val_accuracy: 0.7889\n",
      "Epoch 61/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7815 - val_loss: 0.5000 - val_accuracy: 0.7778\n",
      "Epoch 62/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5551 - accuracy: 0.7840 - val_loss: 0.4968 - val_accuracy: 0.7889\n",
      "Epoch 63/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7853 - val_loss: 0.4967 - val_accuracy: 0.8000\n",
      "Epoch 64/600\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.5499 - accuracy: 0.7690 - val_loss: 0.4903 - val_accuracy: 0.8000\n",
      "Epoch 65/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.8040 - val_loss: 0.4954 - val_accuracy: 0.8000\n",
      "Epoch 66/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7815 - val_loss: 0.4878 - val_accuracy: 0.7889\n",
      "Epoch 67/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5560 - accuracy: 0.7803 - val_loss: 0.4933 - val_accuracy: 0.8000\n",
      "Epoch 68/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7790 - val_loss: 0.4919 - val_accuracy: 0.8000\n",
      "Epoch 69/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5575 - accuracy: 0.7615 - val_loss: 0.4965 - val_accuracy: 0.7889\n",
      "Epoch 70/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7928 - val_loss: 0.4826 - val_accuracy: 0.7889\n",
      "Epoch 71/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7715 - val_loss: 0.4847 - val_accuracy: 0.8000\n",
      "Epoch 72/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5282 - accuracy: 0.7828 - val_loss: 0.4804 - val_accuracy: 0.8000\n",
      "Epoch 73/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5483 - accuracy: 0.7765 - val_loss: 0.4773 - val_accuracy: 0.8000\n",
      "Epoch 74/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7853 - val_loss: 0.4766 - val_accuracy: 0.7889\n",
      "Epoch 75/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.7740 - val_loss: 0.4775 - val_accuracy: 0.7889\n",
      "Epoch 76/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.7703 - val_loss: 0.4810 - val_accuracy: 0.7889\n",
      "Epoch 77/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7740 - val_loss: 0.4793 - val_accuracy: 0.7889\n",
      "Epoch 78/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5300 - accuracy: 0.7978 - val_loss: 0.4769 - val_accuracy: 0.7889\n",
      "Epoch 79/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7728 - val_loss: 0.4739 - val_accuracy: 0.7889\n",
      "Epoch 80/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7903 - val_loss: 0.4785 - val_accuracy: 0.7889\n",
      "Epoch 81/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7790 - val_loss: 0.4763 - val_accuracy: 0.7889\n",
      "Epoch 82/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5438 - accuracy: 0.7890 - val_loss: 0.4802 - val_accuracy: 0.7778\n",
      "Epoch 83/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5444 - accuracy: 0.7853 - val_loss: 0.4803 - val_accuracy: 0.7778\n",
      "Epoch 84/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5222 - accuracy: 0.7940 - val_loss: 0.4952 - val_accuracy: 0.8000\n",
      "Epoch 85/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5369 - accuracy: 0.7665 - val_loss: 0.4755 - val_accuracy: 0.7889\n",
      "Epoch 86/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5294 - accuracy: 0.7678 - val_loss: 0.4701 - val_accuracy: 0.7889\n",
      "Epoch 87/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5430 - accuracy: 0.7765 - val_loss: 0.4753 - val_accuracy: 0.7778\n",
      "Epoch 88/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.7953 - val_loss: 0.4693 - val_accuracy: 0.7889\n",
      "Epoch 89/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7753 - val_loss: 0.4645 - val_accuracy: 0.7889\n",
      "Epoch 90/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5254 - accuracy: 0.7853 - val_loss: 0.4694 - val_accuracy: 0.7889\n",
      "Epoch 91/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5355 - accuracy: 0.7840 - val_loss: 0.4664 - val_accuracy: 0.7889\n",
      "Epoch 92/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7815 - val_loss: 0.4561 - val_accuracy: 0.7889\n",
      "Epoch 93/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.7653 - val_loss: 0.4620 - val_accuracy: 0.8000\n",
      "Epoch 94/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5421 - accuracy: 0.7690 - val_loss: 0.4726 - val_accuracy: 0.7778\n",
      "Epoch 95/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5295 - accuracy: 0.7878 - val_loss: 0.4665 - val_accuracy: 0.7889\n",
      "Epoch 96/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5169 - accuracy: 0.8015 - val_loss: 0.4807 - val_accuracy: 0.7778\n",
      "Epoch 97/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.7740 - val_loss: 0.4837 - val_accuracy: 0.7778\n",
      "Epoch 98/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7815 - val_loss: 0.4723 - val_accuracy: 0.7889\n",
      "Epoch 99/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.7728 - val_loss: 0.4910 - val_accuracy: 0.8111\n",
      "Epoch 100/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7790 - val_loss: 0.4704 - val_accuracy: 0.7778\n",
      "Epoch 101/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5217 - accuracy: 0.7803 - val_loss: 0.4736 - val_accuracy: 0.7778\n",
      "Epoch 102/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7815 - val_loss: 0.4663 - val_accuracy: 0.7889\n",
      "Epoch 103/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5256 - accuracy: 0.7840 - val_loss: 0.4623 - val_accuracy: 0.7889\n",
      "Epoch 104/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5147 - accuracy: 0.7878 - val_loss: 0.4593 - val_accuracy: 0.7889\n",
      "Epoch 105/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5401 - accuracy: 0.7778 - val_loss: 0.4711 - val_accuracy: 0.7778\n",
      "Epoch 106/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5061 - accuracy: 0.7790 - val_loss: 0.4591 - val_accuracy: 0.7889\n",
      "Epoch 107/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5437 - accuracy: 0.7890 - val_loss: 0.4605 - val_accuracy: 0.7889\n",
      "Epoch 108/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5230 - accuracy: 0.7815 - val_loss: 0.4648 - val_accuracy: 0.7778\n",
      "Epoch 109/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5265 - accuracy: 0.7803 - val_loss: 0.4676 - val_accuracy: 0.7778\n",
      "Epoch 110/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7815 - val_loss: 0.4631 - val_accuracy: 0.7889\n",
      "Epoch 111/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5196 - accuracy: 0.7978 - val_loss: 0.4641 - val_accuracy: 0.7889\n",
      "Epoch 112/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.7928 - val_loss: 0.4726 - val_accuracy: 0.7778\n",
      "Epoch 113/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.7978 - val_loss: 0.4521 - val_accuracy: 0.8000\n",
      "Epoch 114/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5207 - accuracy: 0.7928 - val_loss: 0.4728 - val_accuracy: 0.7778\n",
      "Epoch 115/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5339 - accuracy: 0.7553 - val_loss: 0.4606 - val_accuracy: 0.7889\n",
      "Epoch 116/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4985 - accuracy: 0.7878 - val_loss: 0.4649 - val_accuracy: 0.7889\n",
      "Epoch 117/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7778 - val_loss: 0.4644 - val_accuracy: 0.7889\n",
      "Epoch 118/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.7890 - val_loss: 0.4653 - val_accuracy: 0.7778\n",
      "Epoch 119/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5188 - accuracy: 0.7815 - val_loss: 0.4554 - val_accuracy: 0.7889\n",
      "Epoch 120/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.7903 - val_loss: 0.5027 - val_accuracy: 0.8111\n",
      "Epoch 121/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5298 - accuracy: 0.7728 - val_loss: 0.4781 - val_accuracy: 0.8000\n",
      "Epoch 122/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7853 - val_loss: 0.4687 - val_accuracy: 0.7778\n",
      "Epoch 123/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.7940 - val_loss: 0.4829 - val_accuracy: 0.8000\n",
      "Epoch 124/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.7803 - val_loss: 0.4661 - val_accuracy: 0.7778\n",
      "Epoch 125/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5284 - accuracy: 0.7790 - val_loss: 0.4636 - val_accuracy: 0.7889\n",
      "Epoch 126/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5137 - accuracy: 0.7928 - val_loss: 0.4573 - val_accuracy: 0.7889\n",
      "Epoch 127/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5299 - accuracy: 0.7778 - val_loss: 0.4625 - val_accuracy: 0.7889\n",
      "Epoch 128/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5279 - accuracy: 0.7803 - val_loss: 0.4820 - val_accuracy: 0.8000\n",
      "Epoch 129/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4966 - accuracy: 0.7778 - val_loss: 0.4592 - val_accuracy: 0.7778\n",
      "Epoch 130/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5267 - accuracy: 0.7890 - val_loss: 0.4529 - val_accuracy: 0.8000\n",
      "Epoch 131/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5420 - accuracy: 0.7803 - val_loss: 0.4710 - val_accuracy: 0.7778\n",
      "Epoch 132/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5343 - accuracy: 0.7940 - val_loss: 0.4813 - val_accuracy: 0.8000\n",
      "Epoch 133/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5329 - accuracy: 0.7828 - val_loss: 0.4937 - val_accuracy: 0.8111\n",
      "Epoch 134/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5164 - accuracy: 0.7728 - val_loss: 0.4727 - val_accuracy: 0.7778\n",
      "Epoch 135/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5015 - accuracy: 0.7965 - val_loss: 0.4784 - val_accuracy: 0.8000\n",
      "Epoch 136/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7878 - val_loss: 0.4577 - val_accuracy: 0.7889\n",
      "Epoch 137/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.7890 - val_loss: 0.4566 - val_accuracy: 0.7889\n",
      "Epoch 138/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5060 - accuracy: 0.7990 - val_loss: 0.4914 - val_accuracy: 0.8000\n",
      "Epoch 139/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5102 - accuracy: 0.7840 - val_loss: 0.4739 - val_accuracy: 0.7778\n",
      "Epoch 140/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5069 - accuracy: 0.7903 - val_loss: 0.4685 - val_accuracy: 0.7778\n",
      "Epoch 141/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4980 - accuracy: 0.7890 - val_loss: 0.4633 - val_accuracy: 0.7889\n",
      "Epoch 142/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5020 - accuracy: 0.7965 - val_loss: 0.4586 - val_accuracy: 0.7889\n",
      "Epoch 143/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.8015 - val_loss: 0.4580 - val_accuracy: 0.7889\n",
      "Epoch 144/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5047 - accuracy: 0.7865 - val_loss: 0.4587 - val_accuracy: 0.7778\n",
      "Epoch 145/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5149 - accuracy: 0.7928 - val_loss: 0.4506 - val_accuracy: 0.8000\n",
      "Epoch 146/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7915 - val_loss: 0.4560 - val_accuracy: 0.7889\n",
      "Epoch 147/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5117 - accuracy: 0.7903 - val_loss: 0.4529 - val_accuracy: 0.8000\n",
      "Epoch 148/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.8002 - val_loss: 0.4629 - val_accuracy: 0.7889\n",
      "Epoch 149/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7990 - val_loss: 0.4657 - val_accuracy: 0.7778\n",
      "Epoch 150/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7878 - val_loss: 0.4623 - val_accuracy: 0.7889\n",
      "Epoch 151/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5189 - accuracy: 0.7865 - val_loss: 0.4671 - val_accuracy: 0.7889\n",
      "Epoch 152/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7978 - val_loss: 0.4686 - val_accuracy: 0.7778\n",
      "Epoch 153/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7915 - val_loss: 0.4552 - val_accuracy: 0.8000\n",
      "Epoch 154/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7915 - val_loss: 0.4795 - val_accuracy: 0.7778\n",
      "Epoch 155/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5101 - accuracy: 0.7753 - val_loss: 0.4563 - val_accuracy: 0.8000\n",
      "Epoch 156/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7915 - val_loss: 0.4563 - val_accuracy: 0.8000\n",
      "Epoch 157/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.7853 - val_loss: 0.4500 - val_accuracy: 0.7889\n",
      "Epoch 158/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5067 - accuracy: 0.7940 - val_loss: 0.4543 - val_accuracy: 0.8000\n",
      "Epoch 159/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8015 - val_loss: 0.4741 - val_accuracy: 0.7778\n",
      "Epoch 160/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7865 - val_loss: 0.4632 - val_accuracy: 0.7889\n",
      "Epoch 161/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5025 - accuracy: 0.7865 - val_loss: 0.4545 - val_accuracy: 0.8000\n",
      "Epoch 162/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5125 - accuracy: 0.7915 - val_loss: 0.4464 - val_accuracy: 0.8000\n",
      "Epoch 163/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.7965 - val_loss: 0.4545 - val_accuracy: 0.7889\n",
      "Epoch 164/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4905 - accuracy: 0.7878 - val_loss: 0.4514 - val_accuracy: 0.7778\n",
      "Epoch 165/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7828 - val_loss: 0.4571 - val_accuracy: 0.8000\n",
      "Epoch 166/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5062 - accuracy: 0.7990 - val_loss: 0.4629 - val_accuracy: 0.8000\n",
      "Epoch 167/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.8065 - val_loss: 0.4557 - val_accuracy: 0.8000\n",
      "Epoch 168/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.8102 - val_loss: 0.4589 - val_accuracy: 0.8000\n",
      "Epoch 169/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5116 - accuracy: 0.7903 - val_loss: 0.4444 - val_accuracy: 0.7889\n",
      "Epoch 170/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.8152 - val_loss: 0.4553 - val_accuracy: 0.8000\n",
      "Epoch 171/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.8052 - val_loss: 0.4529 - val_accuracy: 0.7889\n",
      "Epoch 172/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7865 - val_loss: 0.4545 - val_accuracy: 0.7889\n",
      "Epoch 173/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.7915 - val_loss: 0.4591 - val_accuracy: 0.8000\n",
      "Epoch 174/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.8002 - val_loss: 0.4740 - val_accuracy: 0.7889\n",
      "Epoch 175/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7990 - val_loss: 0.4687 - val_accuracy: 0.7889\n",
      "Epoch 176/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4935 - accuracy: 0.7940 - val_loss: 0.5023 - val_accuracy: 0.8000\n",
      "Epoch 177/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4838 - accuracy: 0.8015 - val_loss: 0.4891 - val_accuracy: 0.8000\n",
      "Epoch 178/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7928 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 179/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.7978 - val_loss: 0.4923 - val_accuracy: 0.8000\n",
      "Epoch 180/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4988 - accuracy: 0.7965 - val_loss: 0.4934 - val_accuracy: 0.8000\n",
      "Epoch 181/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5145 - accuracy: 0.7940 - val_loss: 0.4717 - val_accuracy: 0.7889\n",
      "Epoch 182/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4928 - accuracy: 0.7978 - val_loss: 0.4636 - val_accuracy: 0.7889\n",
      "Epoch 183/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5074 - accuracy: 0.7965 - val_loss: 0.4748 - val_accuracy: 0.7889\n",
      "Epoch 184/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.8065 - val_loss: 0.4691 - val_accuracy: 0.7889\n",
      "Epoch 185/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.7965 - val_loss: 0.4489 - val_accuracy: 0.7889\n",
      "Epoch 186/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4997 - accuracy: 0.8052 - val_loss: 0.4558 - val_accuracy: 0.8000\n",
      "Epoch 187/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.8090 - val_loss: 0.4923 - val_accuracy: 0.8000\n",
      "Epoch 188/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4934 - accuracy: 0.7865 - val_loss: 0.4559 - val_accuracy: 0.7889\n",
      "Epoch 189/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.7928 - val_loss: 0.4829 - val_accuracy: 0.7889\n",
      "Epoch 190/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8015 - val_loss: 0.5107 - val_accuracy: 0.8111\n",
      "Epoch 191/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.7865 - val_loss: 0.4998 - val_accuracy: 0.8111\n",
      "Epoch 192/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5007 - accuracy: 0.7865 - val_loss: 0.4727 - val_accuracy: 0.7889\n",
      "Epoch 193/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.8102 - val_loss: 0.4727 - val_accuracy: 0.7889\n",
      "Epoch 194/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4954 - accuracy: 0.7928 - val_loss: 0.4516 - val_accuracy: 0.8000\n",
      "Epoch 195/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4973 - accuracy: 0.7890 - val_loss: 0.4523 - val_accuracy: 0.8000\n",
      "Epoch 196/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4805 - accuracy: 0.8027 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 197/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4965 - accuracy: 0.8090 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 198/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4868 - accuracy: 0.8065 - val_loss: 0.4528 - val_accuracy: 0.7889\n",
      "Epoch 199/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7840 - val_loss: 0.4528 - val_accuracy: 0.7889\n",
      "Epoch 200/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4947 - accuracy: 0.7965 - val_loss: 0.4821 - val_accuracy: 0.8111\n",
      "Epoch 201/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5019 - accuracy: 0.7965 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 202/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4887 - accuracy: 0.7928 - val_loss: 0.4618 - val_accuracy: 0.7889\n",
      "Epoch 203/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4843 - accuracy: 0.8052 - val_loss: 0.4583 - val_accuracy: 0.7889\n",
      "Epoch 204/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5022 - accuracy: 0.7965 - val_loss: 0.4489 - val_accuracy: 0.7889\n",
      "Epoch 205/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.7990 - val_loss: 0.4518 - val_accuracy: 0.8000\n",
      "Epoch 206/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7915 - val_loss: 0.4518 - val_accuracy: 0.8000\n",
      "Epoch 207/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.8040 - val_loss: 0.4429 - val_accuracy: 0.8000\n",
      "Epoch 208/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5024 - accuracy: 0.7903 - val_loss: 0.4551 - val_accuracy: 0.7889\n",
      "Epoch 209/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5011 - accuracy: 0.8102 - val_loss: 0.4420 - val_accuracy: 0.8111\n",
      "Epoch 210/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5070 - accuracy: 0.7940 - val_loss: 0.4610 - val_accuracy: 0.8111\n",
      "Epoch 211/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4751 - accuracy: 0.7978 - val_loss: 0.4559 - val_accuracy: 0.7889\n",
      "Epoch 212/600\n",
      "26/26 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7928 - val_loss: 0.5244 - val_accuracy: 0.8111\n",
      "Epoch 213/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7928 - val_loss: 0.4688 - val_accuracy: 0.7778\n",
      "Epoch 214/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4810 - accuracy: 0.7890 - val_loss: 0.4585 - val_accuracy: 0.7889\n",
      "Epoch 215/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.7903 - val_loss: 0.4690 - val_accuracy: 0.7778\n",
      "Epoch 216/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.7953 - val_loss: 0.4631 - val_accuracy: 0.7778\n",
      "Epoch 217/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4923 - accuracy: 0.7840 - val_loss: 0.4561 - val_accuracy: 0.7889\n",
      "Epoch 218/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7978 - val_loss: 0.5018 - val_accuracy: 0.8000\n",
      "Epoch 219/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4890 - accuracy: 0.7915 - val_loss: 0.4618 - val_accuracy: 0.8000\n",
      "Epoch 220/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4960 - accuracy: 0.7978 - val_loss: 0.4607 - val_accuracy: 0.8000\n",
      "Epoch 221/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4878 - accuracy: 0.7940 - val_loss: 0.4578 - val_accuracy: 0.7889\n",
      "Epoch 222/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.8090 - val_loss: 0.4486 - val_accuracy: 0.7889\n",
      "Epoch 223/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4930 - accuracy: 0.7890 - val_loss: 0.4417 - val_accuracy: 0.8000\n",
      "Epoch 224/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4871 - accuracy: 0.7953 - val_loss: 0.4515 - val_accuracy: 0.7889\n",
      "Epoch 225/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4925 - accuracy: 0.7890 - val_loss: 0.4770 - val_accuracy: 0.8222\n",
      "Epoch 226/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7815 - val_loss: 0.4559 - val_accuracy: 0.7889\n",
      "Epoch 227/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4883 - accuracy: 0.7965 - val_loss: 0.4548 - val_accuracy: 0.7889\n",
      "Epoch 228/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4917 - accuracy: 0.8002 - val_loss: 0.4485 - val_accuracy: 0.8000\n",
      "Epoch 229/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.7928 - val_loss: 0.4506 - val_accuracy: 0.8000\n",
      "Epoch 230/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4841 - accuracy: 0.7940 - val_loss: 0.4757 - val_accuracy: 0.8000\n",
      "Epoch 231/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8090 - val_loss: 0.5164 - val_accuracy: 0.8111\n",
      "Epoch 232/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4972 - accuracy: 0.7953 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 233/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7928 - val_loss: 0.4869 - val_accuracy: 0.7778\n",
      "Epoch 234/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.7915 - val_loss: 0.4959 - val_accuracy: 0.8111\n",
      "Epoch 235/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4814 - accuracy: 0.8002 - val_loss: 0.4573 - val_accuracy: 0.7889\n",
      "Epoch 236/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4931 - accuracy: 0.7890 - val_loss: 0.4523 - val_accuracy: 0.8000\n",
      "Epoch 237/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7965 - val_loss: 0.4922 - val_accuracy: 0.7889\n",
      "Epoch 238/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4837 - accuracy: 0.7928 - val_loss: 0.4617 - val_accuracy: 0.8111\n",
      "Epoch 239/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.8052 - val_loss: 0.4650 - val_accuracy: 0.7889\n",
      "Epoch 240/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4740 - accuracy: 0.7928 - val_loss: 0.4466 - val_accuracy: 0.8000\n",
      "Epoch 241/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.5050 - accuracy: 0.7978 - val_loss: 0.4513 - val_accuracy: 0.7778\n",
      "Epoch 242/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4848 - accuracy: 0.8102 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 243/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.8065 - val_loss: 0.4614 - val_accuracy: 0.8000\n",
      "Epoch 244/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8102 - val_loss: 0.4589 - val_accuracy: 0.7889\n",
      "Epoch 245/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7928 - val_loss: 0.4498 - val_accuracy: 0.8000\n",
      "Epoch 246/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4903 - accuracy: 0.7890 - val_loss: 0.4604 - val_accuracy: 0.7889\n",
      "Epoch 247/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4832 - accuracy: 0.7915 - val_loss: 0.4895 - val_accuracy: 0.8222\n",
      "Epoch 248/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4894 - accuracy: 0.7965 - val_loss: 0.4768 - val_accuracy: 0.8000\n",
      "Epoch 249/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4835 - accuracy: 0.8040 - val_loss: 0.5225 - val_accuracy: 0.8111\n",
      "Epoch 250/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7928 - val_loss: 0.4795 - val_accuracy: 0.8000\n",
      "Epoch 251/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.7990 - val_loss: 0.4827 - val_accuracy: 0.8000\n",
      "Epoch 252/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4667 - accuracy: 0.8102 - val_loss: 0.4731 - val_accuracy: 0.8111\n",
      "Epoch 253/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4839 - accuracy: 0.8015 - val_loss: 0.4524 - val_accuracy: 0.7889\n",
      "Epoch 254/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4825 - accuracy: 0.8065 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 255/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4870 - accuracy: 0.7915 - val_loss: 0.4494 - val_accuracy: 0.7889\n",
      "Epoch 256/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8052 - val_loss: 0.4508 - val_accuracy: 0.7889\n",
      "Epoch 257/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4828 - accuracy: 0.7953 - val_loss: 0.4516 - val_accuracy: 0.7889\n",
      "Epoch 258/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4769 - accuracy: 0.8027 - val_loss: 0.4569 - val_accuracy: 0.7889\n",
      "Epoch 259/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8040 - val_loss: 0.4559 - val_accuracy: 0.8000\n",
      "Epoch 260/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4862 - accuracy: 0.8065 - val_loss: 0.4579 - val_accuracy: 0.8000\n",
      "Epoch 261/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4849 - accuracy: 0.8027 - val_loss: 0.4489 - val_accuracy: 0.8000\n",
      "Epoch 262/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4915 - accuracy: 0.7978 - val_loss: 0.4533 - val_accuracy: 0.7889\n",
      "Epoch 263/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.8040 - val_loss: 0.4474 - val_accuracy: 0.8111\n",
      "Epoch 264/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.8102 - val_loss: 0.4568 - val_accuracy: 0.8000\n",
      "Epoch 265/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8115 - val_loss: 0.4597 - val_accuracy: 0.7889\n",
      "Epoch 266/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.8040 - val_loss: 0.4615 - val_accuracy: 0.7889\n",
      "Epoch 267/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4663 - accuracy: 0.8102 - val_loss: 0.4554 - val_accuracy: 0.7889\n",
      "Epoch 268/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.8002 - val_loss: 0.4568 - val_accuracy: 0.7889\n",
      "Epoch 269/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.8140 - val_loss: 0.4501 - val_accuracy: 0.8000\n",
      "Epoch 270/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4761 - accuracy: 0.8127 - val_loss: 0.4461 - val_accuracy: 0.7889\n",
      "Epoch 271/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4927 - accuracy: 0.8115 - val_loss: 0.4473 - val_accuracy: 0.7778\n",
      "Epoch 272/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.8002 - val_loss: 0.4543 - val_accuracy: 0.7889\n",
      "Epoch 273/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.7890 - val_loss: 0.4555 - val_accuracy: 0.8111\n",
      "Epoch 274/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.7828 - val_loss: 0.4720 - val_accuracy: 0.7889\n",
      "Epoch 275/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8115 - val_loss: 0.4533 - val_accuracy: 0.8000\n",
      "Epoch 276/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4762 - accuracy: 0.8115 - val_loss: 0.4704 - val_accuracy: 0.7889\n",
      "Epoch 277/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.8052 - val_loss: 0.4510 - val_accuracy: 0.8000\n",
      "Epoch 278/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.8027 - val_loss: 0.4826 - val_accuracy: 0.8000\n",
      "Epoch 279/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.8152 - val_loss: 0.4670 - val_accuracy: 0.7889\n",
      "Epoch 280/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.8077 - val_loss: 0.4615 - val_accuracy: 0.8111\n",
      "Epoch 281/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4644 - accuracy: 0.8077 - val_loss: 0.4946 - val_accuracy: 0.8000\n",
      "Epoch 282/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.7965 - val_loss: 0.4433 - val_accuracy: 0.7889\n",
      "Epoch 283/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4816 - accuracy: 0.8027 - val_loss: 0.4523 - val_accuracy: 0.7778\n",
      "Epoch 284/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4850 - accuracy: 0.7878 - val_loss: 0.4551 - val_accuracy: 0.8000\n",
      "Epoch 285/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4831 - accuracy: 0.8140 - val_loss: 0.4594 - val_accuracy: 0.8000\n",
      "Epoch 286/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.8102 - val_loss: 0.4604 - val_accuracy: 0.7889\n",
      "Epoch 287/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4773 - accuracy: 0.8077 - val_loss: 0.4553 - val_accuracy: 0.7889\n",
      "Epoch 288/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.8140 - val_loss: 0.4780 - val_accuracy: 0.7889\n",
      "Epoch 289/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4599 - accuracy: 0.7928 - val_loss: 0.4554 - val_accuracy: 0.8000\n",
      "Epoch 290/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4840 - accuracy: 0.7940 - val_loss: 0.4899 - val_accuracy: 0.8111\n",
      "Epoch 291/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8102 - val_loss: 0.4641 - val_accuracy: 0.8000\n",
      "Epoch 292/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4728 - accuracy: 0.8090 - val_loss: 0.4615 - val_accuracy: 0.8000\n",
      "Epoch 293/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4743 - accuracy: 0.8065 - val_loss: 0.4538 - val_accuracy: 0.7889\n",
      "Epoch 294/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4826 - accuracy: 0.8002 - val_loss: 0.4457 - val_accuracy: 0.7778\n",
      "Epoch 295/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4793 - accuracy: 0.8102 - val_loss: 0.4492 - val_accuracy: 0.7778\n",
      "Epoch 296/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.8015 - val_loss: 0.4572 - val_accuracy: 0.7889\n",
      "Epoch 297/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.8152 - val_loss: 0.5104 - val_accuracy: 0.8000\n",
      "Epoch 298/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.7990 - val_loss: 0.4761 - val_accuracy: 0.8000\n",
      "Epoch 299/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8165 - val_loss: 0.4748 - val_accuracy: 0.8000\n",
      "Epoch 300/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.8102 - val_loss: 0.4539 - val_accuracy: 0.7778\n",
      "Epoch 301/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.8127 - val_loss: 0.4856 - val_accuracy: 0.8000\n",
      "Epoch 302/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.8177 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
      "Epoch 303/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.8027 - val_loss: 0.4553 - val_accuracy: 0.7889\n",
      "Epoch 304/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8065 - val_loss: 0.4524 - val_accuracy: 0.7778\n",
      "Epoch 305/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4735 - accuracy: 0.8127 - val_loss: 0.4696 - val_accuracy: 0.8000\n",
      "Epoch 306/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.7915 - val_loss: 0.4563 - val_accuracy: 0.7889\n",
      "Epoch 307/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8115 - val_loss: 0.4572 - val_accuracy: 0.7889\n",
      "Epoch 308/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.8015 - val_loss: 0.4544 - val_accuracy: 0.7778\n",
      "Epoch 309/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7990 - val_loss: 0.4497 - val_accuracy: 0.7889\n",
      "Epoch 310/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4783 - accuracy: 0.8065 - val_loss: 0.4564 - val_accuracy: 0.7778\n",
      "Epoch 311/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8152 - val_loss: 0.4576 - val_accuracy: 0.7889\n",
      "Epoch 312/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4779 - accuracy: 0.8090 - val_loss: 0.4510 - val_accuracy: 0.7889\n",
      "Epoch 313/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8140 - val_loss: 0.4541 - val_accuracy: 0.7889\n",
      "Epoch 314/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4906 - accuracy: 0.7940 - val_loss: 0.4665 - val_accuracy: 0.7889\n",
      "Epoch 315/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4884 - accuracy: 0.8115 - val_loss: 0.5241 - val_accuracy: 0.8222\n",
      "Epoch 316/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4702 - accuracy: 0.8140 - val_loss: 0.4746 - val_accuracy: 0.7889\n",
      "Epoch 317/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4744 - accuracy: 0.8040 - val_loss: 0.4614 - val_accuracy: 0.7889\n",
      "Epoch 318/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4676 - accuracy: 0.7990 - val_loss: 0.4670 - val_accuracy: 0.7889\n",
      "Epoch 319/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.8065 - val_loss: 0.4565 - val_accuracy: 0.7889\n",
      "Epoch 320/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8090 - val_loss: 0.4571 - val_accuracy: 0.7889\n",
      "Epoch 321/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4678 - accuracy: 0.8052 - val_loss: 0.4716 - val_accuracy: 0.8000\n",
      "Epoch 322/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.8165 - val_loss: 0.4577 - val_accuracy: 0.7778\n",
      "Epoch 323/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.8052 - val_loss: 0.4723 - val_accuracy: 0.8000\n",
      "Epoch 324/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.8065 - val_loss: 0.4539 - val_accuracy: 0.8000\n",
      "Epoch 325/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4859 - accuracy: 0.8027 - val_loss: 0.4884 - val_accuracy: 0.8000\n",
      "Epoch 326/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4590 - accuracy: 0.8002 - val_loss: 0.4611 - val_accuracy: 0.8000\n",
      "Epoch 327/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.8002 - val_loss: 0.4755 - val_accuracy: 0.7889\n",
      "Epoch 328/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8152 - val_loss: 0.4690 - val_accuracy: 0.8000\n",
      "Epoch 329/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4755 - accuracy: 0.8015 - val_loss: 0.4984 - val_accuracy: 0.8333\n",
      "Epoch 330/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4726 - accuracy: 0.8027 - val_loss: 0.4950 - val_accuracy: 0.8333\n",
      "Epoch 331/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.7990 - val_loss: 0.4550 - val_accuracy: 0.7889\n",
      "Epoch 332/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8065 - val_loss: 0.4961 - val_accuracy: 0.8000\n",
      "Epoch 333/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.8090 - val_loss: 0.4877 - val_accuracy: 0.8000\n",
      "Epoch 334/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4680 - accuracy: 0.8165 - val_loss: 0.4633 - val_accuracy: 0.7778\n",
      "Epoch 335/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8227 - val_loss: 0.4628 - val_accuracy: 0.7889\n",
      "Epoch 336/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4967 - accuracy: 0.8040 - val_loss: 0.4612 - val_accuracy: 0.7778\n",
      "Epoch 337/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.8202 - val_loss: 0.4618 - val_accuracy: 0.7778\n",
      "Epoch 338/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8177 - val_loss: 0.4665 - val_accuracy: 0.7889\n",
      "Epoch 339/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.7990 - val_loss: 0.4632 - val_accuracy: 0.7778\n",
      "Epoch 340/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4792 - accuracy: 0.8177 - val_loss: 0.4685 - val_accuracy: 0.8000\n",
      "Epoch 341/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4760 - accuracy: 0.8215 - val_loss: 0.4595 - val_accuracy: 0.7889\n",
      "Epoch 342/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4750 - accuracy: 0.8090 - val_loss: 0.4579 - val_accuracy: 0.7778\n",
      "Epoch 343/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4866 - accuracy: 0.7940 - val_loss: 0.4667 - val_accuracy: 0.7889\n",
      "Epoch 344/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4716 - accuracy: 0.8065 - val_loss: 0.4712 - val_accuracy: 0.8000\n",
      "Epoch 345/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4627 - accuracy: 0.8090 - val_loss: 0.4713 - val_accuracy: 0.8111\n",
      "Epoch 346/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8140 - val_loss: 0.4589 - val_accuracy: 0.7889\n",
      "Epoch 347/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4727 - accuracy: 0.8115 - val_loss: 0.4545 - val_accuracy: 0.7889\n",
      "Epoch 348/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.8127 - val_loss: 0.4597 - val_accuracy: 0.8000\n",
      "Epoch 349/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8140 - val_loss: 0.4503 - val_accuracy: 0.7889\n",
      "Epoch 350/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4689 - accuracy: 0.8102 - val_loss: 0.4522 - val_accuracy: 0.7889\n",
      "Epoch 351/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4685 - accuracy: 0.8027 - val_loss: 0.4655 - val_accuracy: 0.7889\n",
      "Epoch 352/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4765 - accuracy: 0.7990 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 353/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4781 - accuracy: 0.8127 - val_loss: 0.4707 - val_accuracy: 0.8000\n",
      "Epoch 354/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8152 - val_loss: 0.4605 - val_accuracy: 0.7889\n",
      "Epoch 355/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.8115 - val_loss: 0.4531 - val_accuracy: 0.7889\n",
      "Epoch 356/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8227 - val_loss: 0.4584 - val_accuracy: 0.7889\n",
      "Epoch 357/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4675 - accuracy: 0.8040 - val_loss: 0.4585 - val_accuracy: 0.7778\n",
      "Epoch 358/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8227 - val_loss: 0.4837 - val_accuracy: 0.8444\n",
      "Epoch 359/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4770 - accuracy: 0.8127 - val_loss: 0.4319 - val_accuracy: 0.8111\n",
      "Epoch 360/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4708 - accuracy: 0.8090 - val_loss: 0.4505 - val_accuracy: 0.8000\n",
      "Epoch 361/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8202 - val_loss: 0.4827 - val_accuracy: 0.8000\n",
      "Epoch 362/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4697 - accuracy: 0.8015 - val_loss: 0.4493 - val_accuracy: 0.8000\n",
      "Epoch 363/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.8065 - val_loss: 0.4883 - val_accuracy: 0.8000\n",
      "Epoch 364/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4747 - accuracy: 0.8140 - val_loss: 0.4580 - val_accuracy: 0.8000\n",
      "Epoch 365/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4660 - accuracy: 0.8152 - val_loss: 0.4455 - val_accuracy: 0.7889\n",
      "Epoch 366/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.8152 - val_loss: 0.4364 - val_accuracy: 0.8000\n",
      "Epoch 367/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4652 - accuracy: 0.7953 - val_loss: 0.4701 - val_accuracy: 0.8000\n",
      "Epoch 368/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8165 - val_loss: 0.4371 - val_accuracy: 0.8000\n",
      "Epoch 369/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8015 - val_loss: 0.4488 - val_accuracy: 0.7889\n",
      "Epoch 370/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4629 - accuracy: 0.8065 - val_loss: 0.4561 - val_accuracy: 0.7778\n",
      "Epoch 371/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.8140 - val_loss: 0.4454 - val_accuracy: 0.7889\n",
      "Epoch 372/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8152 - val_loss: 0.4486 - val_accuracy: 0.7889\n",
      "Epoch 373/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8115 - val_loss: 0.4479 - val_accuracy: 0.7889\n",
      "Epoch 374/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.8102 - val_loss: 0.4630 - val_accuracy: 0.8111\n",
      "Epoch 375/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8202 - val_loss: 0.4531 - val_accuracy: 0.7889\n",
      "Epoch 376/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.8140 - val_loss: 0.4385 - val_accuracy: 0.8000\n",
      "Epoch 377/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.8090 - val_loss: 0.4520 - val_accuracy: 0.8000\n",
      "Epoch 378/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8215 - val_loss: 0.4541 - val_accuracy: 0.8000\n",
      "Epoch 379/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8177 - val_loss: 0.4472 - val_accuracy: 0.7889\n",
      "Epoch 380/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8290 - val_loss: 0.4565 - val_accuracy: 0.8111\n",
      "Epoch 381/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8090 - val_loss: 0.4481 - val_accuracy: 0.7889\n",
      "Epoch 382/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8165 - val_loss: 0.4557 - val_accuracy: 0.8000\n",
      "Epoch 383/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4729 - accuracy: 0.7965 - val_loss: 0.4498 - val_accuracy: 0.7889\n",
      "Epoch 384/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.8277 - val_loss: 0.4614 - val_accuracy: 0.7778\n",
      "Epoch 385/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.7928 - val_loss: 0.4574 - val_accuracy: 0.7889\n",
      "Epoch 386/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8040 - val_loss: 0.4793 - val_accuracy: 0.8111\n",
      "Epoch 387/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4725 - accuracy: 0.8002 - val_loss: 0.4678 - val_accuracy: 0.8111\n",
      "Epoch 388/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4666 - accuracy: 0.8040 - val_loss: 0.4632 - val_accuracy: 0.8000\n",
      "Epoch 389/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4609 - accuracy: 0.8152 - val_loss: 0.4667 - val_accuracy: 0.8111\n",
      "Epoch 390/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.8040 - val_loss: 0.4596 - val_accuracy: 0.7778\n",
      "Epoch 391/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4642 - accuracy: 0.7965 - val_loss: 0.4593 - val_accuracy: 0.7889\n",
      "Epoch 392/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.8165 - val_loss: 0.4539 - val_accuracy: 0.7889\n",
      "Epoch 393/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.8127 - val_loss: 0.4924 - val_accuracy: 0.8111\n",
      "Epoch 394/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.8077 - val_loss: 0.4542 - val_accuracy: 0.7889\n",
      "Epoch 395/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.8040 - val_loss: 0.4620 - val_accuracy: 0.8000\n",
      "Epoch 396/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4686 - accuracy: 0.8002 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 397/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8065 - val_loss: 0.4645 - val_accuracy: 0.8222\n",
      "Epoch 398/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8177 - val_loss: 0.4758 - val_accuracy: 0.8111\n",
      "Epoch 399/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8090 - val_loss: 0.4599 - val_accuracy: 0.8000\n",
      "Epoch 400/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8077 - val_loss: 0.4538 - val_accuracy: 0.7889\n",
      "Epoch 401/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4500 - accuracy: 0.8202 - val_loss: 0.4551 - val_accuracy: 0.7889\n",
      "Epoch 402/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8190 - val_loss: 0.5093 - val_accuracy: 0.8333\n",
      "Epoch 403/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.8015 - val_loss: 0.4658 - val_accuracy: 0.8222\n",
      "Epoch 404/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4691 - accuracy: 0.8140 - val_loss: 0.5041 - val_accuracy: 0.8000\n",
      "Epoch 405/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4618 - accuracy: 0.8165 - val_loss: 0.4824 - val_accuracy: 0.8222\n",
      "Epoch 406/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4698 - accuracy: 0.8127 - val_loss: 0.4669 - val_accuracy: 0.7889\n",
      "Epoch 407/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8115 - val_loss: 0.4497 - val_accuracy: 0.8000\n",
      "Epoch 408/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4777 - accuracy: 0.8027 - val_loss: 0.4604 - val_accuracy: 0.7889\n",
      "Epoch 409/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4803 - accuracy: 0.8165 - val_loss: 0.4548 - val_accuracy: 0.7889\n",
      "Epoch 410/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4734 - accuracy: 0.8065 - val_loss: 0.4606 - val_accuracy: 0.7889\n",
      "Epoch 411/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8215 - val_loss: 0.4654 - val_accuracy: 0.7889\n",
      "Epoch 412/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4808 - accuracy: 0.8027 - val_loss: 0.4599 - val_accuracy: 0.7889\n",
      "Epoch 413/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8165 - val_loss: 0.4687 - val_accuracy: 0.7889\n",
      "Epoch 414/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.8152 - val_loss: 0.4717 - val_accuracy: 0.7889\n",
      "Epoch 415/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8077 - val_loss: 0.4617 - val_accuracy: 0.7889\n",
      "Epoch 416/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4623 - accuracy: 0.8127 - val_loss: 0.4710 - val_accuracy: 0.7778\n",
      "Epoch 417/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4671 - accuracy: 0.8090 - val_loss: 0.4759 - val_accuracy: 0.8000\n",
      "Epoch 418/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4617 - accuracy: 0.8190 - val_loss: 0.4532 - val_accuracy: 0.7889\n",
      "Epoch 419/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4809 - accuracy: 0.8040 - val_loss: 0.4543 - val_accuracy: 0.8000\n",
      "Epoch 420/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4780 - accuracy: 0.8165 - val_loss: 0.4631 - val_accuracy: 0.8000\n",
      "Epoch 421/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8027 - val_loss: 0.5129 - val_accuracy: 0.8222\n",
      "Epoch 422/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8177 - val_loss: 0.4653 - val_accuracy: 0.8000\n",
      "Epoch 423/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.8102 - val_loss: 0.4655 - val_accuracy: 0.8000\n",
      "Epoch 424/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8127 - val_loss: 0.4718 - val_accuracy: 0.8111\n",
      "Epoch 425/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8165 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 426/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.8152 - val_loss: 0.4583 - val_accuracy: 0.8000\n",
      "Epoch 427/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8252 - val_loss: 0.4656 - val_accuracy: 0.7889\n",
      "Epoch 428/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8277 - val_loss: 0.4589 - val_accuracy: 0.7889\n",
      "Epoch 429/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4444 - accuracy: 0.8240 - val_loss: 0.4606 - val_accuracy: 0.8000\n",
      "Epoch 430/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8190 - val_loss: 0.4616 - val_accuracy: 0.8000\n",
      "Epoch 431/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4385 - accuracy: 0.8202 - val_loss: 0.4477 - val_accuracy: 0.8000\n",
      "Epoch 432/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8115 - val_loss: 0.4754 - val_accuracy: 0.8000\n",
      "Epoch 433/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.8115 - val_loss: 0.5020 - val_accuracy: 0.8000\n",
      "Epoch 434/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4731 - accuracy: 0.8040 - val_loss: 0.4649 - val_accuracy: 0.8000\n",
      "Epoch 435/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.8077 - val_loss: 0.4925 - val_accuracy: 0.8111\n",
      "Epoch 436/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4606 - accuracy: 0.8077 - val_loss: 0.5123 - val_accuracy: 0.8111\n",
      "Epoch 437/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8165 - val_loss: 0.4804 - val_accuracy: 0.7889\n",
      "Epoch 438/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4545 - accuracy: 0.8127 - val_loss: 0.4683 - val_accuracy: 0.8000\n",
      "Epoch 439/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.8165 - val_loss: 0.4678 - val_accuracy: 0.7889\n",
      "Epoch 440/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4390 - accuracy: 0.8290 - val_loss: 0.4749 - val_accuracy: 0.7889\n",
      "Epoch 441/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4540 - accuracy: 0.8240 - val_loss: 0.4547 - val_accuracy: 0.8000\n",
      "Epoch 442/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8177 - val_loss: 0.4646 - val_accuracy: 0.7889\n",
      "Epoch 443/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8202 - val_loss: 0.4628 - val_accuracy: 0.8000\n",
      "Epoch 444/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8265 - val_loss: 0.5016 - val_accuracy: 0.7111\n",
      "Epoch 445/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5133 - accuracy: 0.7653 - val_loss: 0.4704 - val_accuracy: 0.7778\n",
      "Epoch 446/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.7953 - val_loss: 0.4833 - val_accuracy: 0.8222\n",
      "Epoch 447/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.7928 - val_loss: 0.4742 - val_accuracy: 0.7889\n",
      "Epoch 448/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8002 - val_loss: 0.4748 - val_accuracy: 0.8000\n",
      "Epoch 449/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8165 - val_loss: 0.4636 - val_accuracy: 0.7889\n",
      "Epoch 450/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8077 - val_loss: 0.4591 - val_accuracy: 0.7889\n",
      "Epoch 451/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.8115 - val_loss: 0.4700 - val_accuracy: 0.8000\n",
      "Epoch 452/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4695 - accuracy: 0.8065 - val_loss: 0.4668 - val_accuracy: 0.7889\n",
      "Epoch 453/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8177 - val_loss: 0.4616 - val_accuracy: 0.7889\n",
      "Epoch 454/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.8115 - val_loss: 0.4678 - val_accuracy: 0.7889\n",
      "Epoch 455/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.8065 - val_loss: 0.4655 - val_accuracy: 0.7889\n",
      "Epoch 456/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8090 - val_loss: 0.4579 - val_accuracy: 0.8000\n",
      "Epoch 457/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8127 - val_loss: 0.4667 - val_accuracy: 0.7889\n",
      "Epoch 458/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4571 - accuracy: 0.8177 - val_loss: 0.4625 - val_accuracy: 0.7889\n",
      "Epoch 459/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4621 - accuracy: 0.8127 - val_loss: 0.4660 - val_accuracy: 0.7889\n",
      "Epoch 460/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.8277 - val_loss: 0.4906 - val_accuracy: 0.7889\n",
      "Epoch 461/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8252 - val_loss: 0.4729 - val_accuracy: 0.7889\n",
      "Epoch 462/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8190 - val_loss: 0.4716 - val_accuracy: 0.7889\n",
      "Epoch 463/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4647 - accuracy: 0.8077 - val_loss: 0.4726 - val_accuracy: 0.7889\n",
      "Epoch 464/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8215 - val_loss: 0.4732 - val_accuracy: 0.8000\n",
      "Epoch 465/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8165 - val_loss: 0.4684 - val_accuracy: 0.7889\n",
      "Epoch 466/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.8115 - val_loss: 0.4745 - val_accuracy: 0.8000\n",
      "Epoch 467/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8165 - val_loss: 0.4721 - val_accuracy: 0.7889\n",
      "Epoch 468/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8227 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 469/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8202 - val_loss: 0.4655 - val_accuracy: 0.7889\n",
      "Epoch 470/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.8177 - val_loss: 0.4520 - val_accuracy: 0.8000\n",
      "Epoch 471/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4756 - accuracy: 0.7940 - val_loss: 0.4590 - val_accuracy: 0.8000\n",
      "Epoch 472/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8165 - val_loss: 0.5036 - val_accuracy: 0.8111\n",
      "Epoch 473/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.8215 - val_loss: 0.4728 - val_accuracy: 0.8000\n",
      "Epoch 474/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8227 - val_loss: 0.4735 - val_accuracy: 0.8000\n",
      "Epoch 475/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4635 - accuracy: 0.8177 - val_loss: 0.4825 - val_accuracy: 0.8000\n",
      "Epoch 476/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8265 - val_loss: 0.4757 - val_accuracy: 0.8000\n",
      "Epoch 477/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8152 - val_loss: 0.4757 - val_accuracy: 0.8000\n",
      "Epoch 478/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8165 - val_loss: 0.4873 - val_accuracy: 0.8000\n",
      "Epoch 479/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8140 - val_loss: 0.4738 - val_accuracy: 0.8000\n",
      "Epoch 480/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8252 - val_loss: 0.4674 - val_accuracy: 0.8000\n",
      "Epoch 481/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8090 - val_loss: 0.4573 - val_accuracy: 0.8000\n",
      "Epoch 482/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.8152 - val_loss: 0.4670 - val_accuracy: 0.8000\n",
      "Epoch 483/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8227 - val_loss: 0.4691 - val_accuracy: 0.8222\n",
      "Epoch 484/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8227 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 485/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8202 - val_loss: 0.4665 - val_accuracy: 0.8000\n",
      "Epoch 486/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.8227 - val_loss: 0.4703 - val_accuracy: 0.8000\n",
      "Epoch 487/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8265 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 488/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8177 - val_loss: 0.4638 - val_accuracy: 0.8000\n",
      "Epoch 489/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8227 - val_loss: 0.4731 - val_accuracy: 0.8111\n",
      "Epoch 490/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4480 - accuracy: 0.8252 - val_loss: 0.4534 - val_accuracy: 0.7889\n",
      "Epoch 491/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8202 - val_loss: 0.4647 - val_accuracy: 0.8000\n",
      "Epoch 492/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8177 - val_loss: 0.4594 - val_accuracy: 0.7889\n",
      "Epoch 493/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8277 - val_loss: 0.4965 - val_accuracy: 0.8000\n",
      "Epoch 494/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8127 - val_loss: 0.4871 - val_accuracy: 0.8222\n",
      "Epoch 495/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.8202 - val_loss: 0.4696 - val_accuracy: 0.8000\n",
      "Epoch 496/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8102 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
      "Epoch 497/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4706 - accuracy: 0.8077 - val_loss: 0.4664 - val_accuracy: 0.8000\n",
      "Epoch 498/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8302 - val_loss: 0.4611 - val_accuracy: 0.8000\n",
      "Epoch 499/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.8315 - val_loss: 0.4630 - val_accuracy: 0.8000\n",
      "Epoch 500/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.8065 - val_loss: 0.4634 - val_accuracy: 0.8000\n",
      "Epoch 501/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4459 - accuracy: 0.8240 - val_loss: 0.5176 - val_accuracy: 0.8222\n",
      "Epoch 502/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.8190 - val_loss: 0.4989 - val_accuracy: 0.8111\n",
      "Epoch 503/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8227 - val_loss: 0.4747 - val_accuracy: 0.8111\n",
      "Epoch 504/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8215 - val_loss: 0.4695 - val_accuracy: 0.8111\n",
      "Epoch 505/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8115 - val_loss: 0.4671 - val_accuracy: 0.8000\n",
      "Epoch 506/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4569 - accuracy: 0.8152 - val_loss: 0.4715 - val_accuracy: 0.8111\n",
      "Epoch 507/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8227 - val_loss: 0.4639 - val_accuracy: 0.8000\n",
      "Epoch 508/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.8177 - val_loss: 0.4602 - val_accuracy: 0.8000\n",
      "Epoch 509/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8252 - val_loss: 0.4601 - val_accuracy: 0.8000\n",
      "Epoch 510/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4455 - accuracy: 0.8215 - val_loss: 0.4623 - val_accuracy: 0.8000\n",
      "Epoch 511/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8190 - val_loss: 0.4561 - val_accuracy: 0.8000\n",
      "Epoch 512/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.8202 - val_loss: 0.5350 - val_accuracy: 0.7111\n",
      "Epoch 513/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.7378 - val_loss: 0.4824 - val_accuracy: 0.7889\n",
      "Epoch 514/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4701 - accuracy: 0.7953 - val_loss: 0.4800 - val_accuracy: 0.7889\n",
      "Epoch 515/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4800 - accuracy: 0.8015 - val_loss: 0.4767 - val_accuracy: 0.7889\n",
      "Epoch 516/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4637 - accuracy: 0.8065 - val_loss: 0.4811 - val_accuracy: 0.8111\n",
      "Epoch 517/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4615 - accuracy: 0.8102 - val_loss: 0.4814 - val_accuracy: 0.8222\n",
      "Epoch 518/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8215 - val_loss: 0.4726 - val_accuracy: 0.8222\n",
      "Epoch 519/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.4668 - val_accuracy: 0.8111\n",
      "Epoch 520/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4538 - accuracy: 0.8202 - val_loss: 0.4643 - val_accuracy: 0.8111\n",
      "Epoch 521/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.8140 - val_loss: 0.4687 - val_accuracy: 0.8222\n",
      "Epoch 522/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8240 - val_loss: 0.4705 - val_accuracy: 0.8111\n",
      "Epoch 523/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8215 - val_loss: 0.4626 - val_accuracy: 0.8000\n",
      "Epoch 524/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.8052 - val_loss: 0.4750 - val_accuracy: 0.8222\n",
      "Epoch 525/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8040 - val_loss: 0.4684 - val_accuracy: 0.8000\n",
      "Epoch 526/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.8277 - val_loss: 0.4922 - val_accuracy: 0.8222\n",
      "Epoch 527/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.4754 - val_accuracy: 0.8000\n",
      "Epoch 528/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8277 - val_loss: 0.4624 - val_accuracy: 0.7889\n",
      "Epoch 529/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.8090 - val_loss: 0.4654 - val_accuracy: 0.7889\n",
      "Epoch 530/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.8227 - val_loss: 0.4705 - val_accuracy: 0.8000\n",
      "Epoch 531/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8277 - val_loss: 0.4713 - val_accuracy: 0.8000\n",
      "Epoch 532/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8240 - val_loss: 0.4719 - val_accuracy: 0.8000\n",
      "Epoch 533/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8102 - val_loss: 0.4656 - val_accuracy: 0.8000\n",
      "Epoch 534/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4736 - accuracy: 0.8190 - val_loss: 0.4657 - val_accuracy: 0.8000\n",
      "Epoch 535/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4539 - accuracy: 0.8102 - val_loss: 0.4646 - val_accuracy: 0.7778\n",
      "Epoch 536/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.7890 - val_loss: 0.4767 - val_accuracy: 0.7778\n",
      "Epoch 537/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.8152 - val_loss: 0.4810 - val_accuracy: 0.7889\n",
      "Epoch 538/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4381 - accuracy: 0.8165 - val_loss: 0.4940 - val_accuracy: 0.7889\n",
      "Epoch 539/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4533 - accuracy: 0.8102 - val_loss: 0.4685 - val_accuracy: 0.7889\n",
      "Epoch 540/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8002 - val_loss: 0.4797 - val_accuracy: 0.7889\n",
      "Epoch 541/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8227 - val_loss: 0.4805 - val_accuracy: 0.7889\n",
      "Epoch 542/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8140 - val_loss: 0.4952 - val_accuracy: 0.7889\n",
      "Epoch 543/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8190 - val_loss: 0.4743 - val_accuracy: 0.7889\n",
      "Epoch 544/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8240 - val_loss: 0.4713 - val_accuracy: 0.8000\n",
      "Epoch 545/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4541 - accuracy: 0.8215 - val_loss: 0.4706 - val_accuracy: 0.8000\n",
      "Epoch 546/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.8240 - val_loss: 0.4683 - val_accuracy: 0.7889\n",
      "Epoch 547/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8202 - val_loss: 0.4672 - val_accuracy: 0.8000\n",
      "Epoch 548/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8290 - val_loss: 0.4745 - val_accuracy: 0.8000\n",
      "Epoch 549/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8227 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 550/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4587 - accuracy: 0.8102 - val_loss: 0.4628 - val_accuracy: 0.7889\n",
      "Epoch 551/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4310 - accuracy: 0.8165 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 552/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8165 - val_loss: 0.4662 - val_accuracy: 0.7889\n",
      "Epoch 553/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4614 - accuracy: 0.8202 - val_loss: 0.4899 - val_accuracy: 0.8111\n",
      "Epoch 554/600\n",
      "26/26 [==============================] - 0s 5ms/step - loss: 0.4550 - accuracy: 0.8052 - val_loss: 0.4678 - val_accuracy: 0.7889\n",
      "Epoch 555/600\n",
      "26/26 [==============================] - 0s 6ms/step - loss: 0.4722 - accuracy: 0.7928 - val_loss: 0.4719 - val_accuracy: 0.7889\n",
      "Epoch 556/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8152 - val_loss: 0.4914 - val_accuracy: 0.8000\n",
      "Epoch 557/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8277 - val_loss: 0.4813 - val_accuracy: 0.8000\n",
      "Epoch 558/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4534 - accuracy: 0.8215 - val_loss: 0.4718 - val_accuracy: 0.8000\n",
      "Epoch 559/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8302 - val_loss: 0.4719 - val_accuracy: 0.8000\n",
      "Epoch 560/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4649 - accuracy: 0.8102 - val_loss: 0.4698 - val_accuracy: 0.7889\n",
      "Epoch 561/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8302 - val_loss: 0.4715 - val_accuracy: 0.8000\n",
      "Epoch 562/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4631 - accuracy: 0.8115 - val_loss: 0.4669 - val_accuracy: 0.8000\n",
      "Epoch 563/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4329 - accuracy: 0.8190 - val_loss: 0.4652 - val_accuracy: 0.8000\n",
      "Epoch 564/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8127 - val_loss: 0.4692 - val_accuracy: 0.8000\n",
      "Epoch 565/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.8265 - val_loss: 0.4867 - val_accuracy: 0.8000\n",
      "Epoch 566/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8202 - val_loss: 0.4650 - val_accuracy: 0.7889\n",
      "Epoch 567/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8240 - val_loss: 0.4666 - val_accuracy: 0.8000\n",
      "Epoch 568/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8215 - val_loss: 0.4662 - val_accuracy: 0.8000\n",
      "Epoch 569/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4388 - accuracy: 0.8190 - val_loss: 0.4740 - val_accuracy: 0.8000\n",
      "Epoch 570/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8240 - val_loss: 0.4851 - val_accuracy: 0.7889\n",
      "Epoch 571/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8177 - val_loss: 0.4722 - val_accuracy: 0.8000\n",
      "Epoch 572/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8190 - val_loss: 0.4638 - val_accuracy: 0.8111\n",
      "Epoch 573/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8327 - val_loss: 0.5109 - val_accuracy: 0.7889\n",
      "Epoch 574/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.8190 - val_loss: 0.4718 - val_accuracy: 0.8111\n",
      "Epoch 575/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8177 - val_loss: 0.4715 - val_accuracy: 0.8111\n",
      "Epoch 576/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4553 - accuracy: 0.8202 - val_loss: 0.4642 - val_accuracy: 0.8111\n",
      "Epoch 577/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8277 - val_loss: 0.4669 - val_accuracy: 0.8111\n",
      "Epoch 578/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8152 - val_loss: 0.4625 - val_accuracy: 0.8111\n",
      "Epoch 579/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8190 - val_loss: 0.4653 - val_accuracy: 0.8111\n",
      "Epoch 580/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.8140 - val_loss: 0.4609 - val_accuracy: 0.8000\n",
      "Epoch 581/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.7978 - val_loss: 0.4658 - val_accuracy: 0.8000\n",
      "Epoch 582/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8115 - val_loss: 0.4851 - val_accuracy: 0.8000\n",
      "Epoch 583/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4362 - accuracy: 0.8265 - val_loss: 0.4656 - val_accuracy: 0.8000\n",
      "Epoch 584/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4431 - accuracy: 0.8202 - val_loss: 0.4615 - val_accuracy: 0.8111\n",
      "Epoch 585/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8240 - val_loss: 0.4587 - val_accuracy: 0.8111\n",
      "Epoch 586/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8265 - val_loss: 0.4582 - val_accuracy: 0.7778\n",
      "Epoch 587/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4555 - accuracy: 0.8052 - val_loss: 0.4722 - val_accuracy: 0.8000\n",
      "Epoch 588/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8165 - val_loss: 0.4724 - val_accuracy: 0.8000\n",
      "Epoch 589/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8140 - val_loss: 0.4613 - val_accuracy: 0.8000\n",
      "Epoch 590/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8202 - val_loss: 0.4568 - val_accuracy: 0.8000\n",
      "Epoch 591/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8202 - val_loss: 0.4867 - val_accuracy: 0.8000\n",
      "Epoch 592/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.8202 - val_loss: 0.4643 - val_accuracy: 0.8111\n",
      "Epoch 593/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.8215 - val_loss: 0.4671 - val_accuracy: 0.8111\n",
      "Epoch 594/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8302 - val_loss: 0.4665 - val_accuracy: 0.8111\n",
      "Epoch 595/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8265 - val_loss: 0.4589 - val_accuracy: 0.8111\n",
      "Epoch 596/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8252 - val_loss: 0.4636 - val_accuracy: 0.8000\n",
      "Epoch 597/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8277 - val_loss: 0.4544 - val_accuracy: 0.8000\n",
      "Epoch 598/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8115 - val_loss: 0.4632 - val_accuracy: 0.8111\n",
      "Epoch 599/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4392 - accuracy: 0.8277 - val_loss: 0.4589 - val_accuracy: 0.8111\n",
      "Epoch 600/600\n",
      "26/26 [==============================] - 0s 4ms/step - loss: 0.4476 - accuracy: 0.8202 - val_loss: 0.4631 - val_accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, \n",
    "                    validation_data = (X_test, Y_test), \n",
    "                    epochs=NB_EPOCH, \n",
    "                    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:37.335898Z",
     "iopub.status.busy": "2020-10-27T04:10:37.335042Z",
     "iopub.status.idle": "2020-10-27T04:10:37.582778Z",
     "shell.execute_reply": "2020-10-27T04:10:37.582027Z"
    },
    "papermill": {
     "duration": 1.11249,
     "end_time": "2020-10-27T04:10:37.582928",
     "exception": false,
     "start_time": "2020-10-27T04:10:36.470438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(['train','test'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:39.357043Z",
     "iopub.status.busy": "2020-10-27T04:10:39.356208Z",
     "iopub.status.idle": "2020-10-27T04:10:39.410726Z",
     "shell.execute_reply": "2020-10-27T04:10:39.409846Z"
    },
    "papermill": {
     "duration": 0.969554,
     "end_time": "2020-10-27T04:10:39.410894",
     "exception": false,
     "start_time": "2020-10-27T04:10:38.441340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.8000\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate (X_test, Y_test, verbose = VERBOSE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:41.210769Z",
     "iopub.status.busy": "2020-10-27T04:10:41.209618Z",
     "iopub.status.idle": "2020-10-27T04:10:41.214376Z",
     "shell.execute_reply": "2020-10-27T04:10:41.213600Z"
    },
    "papermill": {
     "duration": 0.88362,
     "end_time": "2020-10-27T04:10:41.214515",
     "exception": false,
     "start_time": "2020-10-27T04:10:40.330895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.46311843395233154\n",
      "Test accuracy: 0.800000011920929\n"
     ]
    }
   ],
   "source": [
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:42.999570Z",
     "iopub.status.busy": "2020-10-27T04:10:42.998386Z",
     "iopub.status.idle": "2020-10-27T04:10:43.002201Z",
     "shell.execute_reply": "2020-10-27T04:10:43.002780Z"
    },
    "papermill": {
     "duration": 0.919221,
     "end_time": "2020-10-27T04:10:43.002958",
     "exception": false,
     "start_time": "2020-10-27T04:10:42.083737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_honban = np.array(data[891:])\n",
    "x_test_honban.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:44.752872Z",
     "iopub.status.busy": "2020-10-27T04:10:44.752031Z",
     "iopub.status.idle": "2020-10-27T04:10:44.925625Z",
     "shell.execute_reply": "2020-10-27T04:10:44.926219Z"
    },
    "papermill": {
     "duration": 1.056932,
     "end_time": "2020-10-27T04:10:44.926386",
     "exception": false,
     "start_time": "2020-10-27T04:10:43.869454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.732656  , 0.267344  ],\n",
       "       [0.6404008 , 0.35959914],\n",
       "       [0.7623853 , 0.23761472],\n",
       "       [0.7306336 , 0.26936638],\n",
       "       [0.58810395, 0.41189605],\n",
       "       [0.67836285, 0.32163715],\n",
       "       [0.18044113, 0.81955886],\n",
       "       [0.6648198 , 0.33518028],\n",
       "       [0.11488592, 0.885114  ],\n",
       "       [0.7129195 , 0.28708056],\n",
       "       [0.7379003 , 0.2620997 ],\n",
       "       [0.6632005 , 0.3367995 ],\n",
       "       [0.06624459, 0.9337554 ],\n",
       "       [0.7834007 , 0.21659924],\n",
       "       [0.06637559, 0.93362445],\n",
       "       [0.06742213, 0.9325779 ],\n",
       "       [0.6777326 , 0.3222674 ],\n",
       "       [0.6539849 , 0.3460151 ],\n",
       "       [0.5821969 , 0.4178032 ],\n",
       "       [0.459775  , 0.540225  ],\n",
       "       [0.6696176 , 0.3303824 ],\n",
       "       [0.66032815, 0.33967185],\n",
       "       [0.06630377, 0.9336962 ],\n",
       "       [0.572811  , 0.42718902],\n",
       "       [0.066275  , 0.933725  ],\n",
       "       [0.807388  , 0.19261198],\n",
       "       [0.06629484, 0.93370515],\n",
       "       [0.6595404 , 0.34045961],\n",
       "       [0.651347  , 0.34865302],\n",
       "       [0.6845828 , 0.31541723],\n",
       "       [0.74702287, 0.25297716],\n",
       "       [0.6563536 , 0.34364638],\n",
       "       [0.6282974 , 0.37170267],\n",
       "       [0.6212931 , 0.37870684],\n",
       "       [0.61815935, 0.38184065],\n",
       "       [0.6448077 , 0.3551922 ],\n",
       "       [0.5492326 , 0.4507674 ],\n",
       "       [0.38985068, 0.61014926],\n",
       "       [0.72316945, 0.27683058],\n",
       "       [0.7295086 , 0.27049145],\n",
       "       [0.7225519 , 0.27744803],\n",
       "       [0.627115  , 0.37288493],\n",
       "       [0.7782837 , 0.22171627],\n",
       "       [0.06680994, 0.9331901 ],\n",
       "       [0.06636279, 0.9336372 ],\n",
       "       [0.72344923, 0.2765508 ],\n",
       "       [0.6558042 , 0.34419575],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.0665542 , 0.9334458 ],\n",
       "       [0.6232809 , 0.3767191 ],\n",
       "       [0.60334724, 0.39665276],\n",
       "       [0.6426865 , 0.35731354],\n",
       "       [0.06682646, 0.9331736 ],\n",
       "       [0.06607912, 0.93392086],\n",
       "       [0.64826226, 0.3517377 ],\n",
       "       [0.6565054 , 0.34349456],\n",
       "       [0.7587081 , 0.24129185],\n",
       "       [0.72349805, 0.27650192],\n",
       "       [0.74039716, 0.2596028 ],\n",
       "       [0.06624468, 0.9337554 ],\n",
       "       [0.6914728 , 0.30852714],\n",
       "       [0.68878436, 0.31121567],\n",
       "       [0.6957168 , 0.30428326],\n",
       "       [0.13483317, 0.8651668 ],\n",
       "       [0.07085984, 0.92914015],\n",
       "       [0.06674496, 0.9332551 ],\n",
       "       [0.12336769, 0.87663233],\n",
       "       [0.6639103 , 0.33608967],\n",
       "       [0.6285635 , 0.37143648],\n",
       "       [0.06629121, 0.9337088 ],\n",
       "       [0.14244309, 0.85755694],\n",
       "       [0.70803076, 0.29196924],\n",
       "       [0.5493461 , 0.45065394],\n",
       "       [0.6236285 , 0.37637156],\n",
       "       [0.06624389, 0.9337561 ],\n",
       "       [0.6164954 , 0.38350463],\n",
       "       [0.7378739 , 0.2621261 ],\n",
       "       [0.06637762, 0.93362236],\n",
       "       [0.68165886, 0.3183411 ],\n",
       "       [0.14244309, 0.85755694],\n",
       "       [0.5921544 , 0.40784562],\n",
       "       [0.69019306, 0.30980688],\n",
       "       [0.67088145, 0.3291185 ],\n",
       "       [0.7379003 , 0.2620997 ],\n",
       "       [0.65715575, 0.34284428],\n",
       "       [0.6842096 , 0.31579036],\n",
       "       [0.15620479, 0.84379524],\n",
       "       [0.3295164 , 0.6704836 ],\n",
       "       [0.17076567, 0.8292343 ],\n",
       "       [0.08542237, 0.9145776 ],\n",
       "       [0.5146769 , 0.485323  ],\n",
       "       [0.73792094, 0.26207903],\n",
       "       [0.066293  , 0.93370706],\n",
       "       [0.7378739 , 0.2621261 ],\n",
       "       [0.6162606 , 0.38373938],\n",
       "       [0.7234721 , 0.27652785],\n",
       "       [0.06795499, 0.932045  ],\n",
       "       [0.7378953 , 0.26210472],\n",
       "       [0.36803547, 0.6319645 ],\n",
       "       [0.75184196, 0.24815807],\n",
       "       [0.06639223, 0.9336078 ],\n",
       "       [0.66862404, 0.33137596],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.72716117, 0.27283886],\n",
       "       [0.14222999, 0.85777   ],\n",
       "       [0.7318218 , 0.2681782 ],\n",
       "       [0.680033  , 0.31996697],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.7377605 , 0.26223958],\n",
       "       [0.637725  , 0.36227497],\n",
       "       [0.6825578 , 0.3174422 ],\n",
       "       [0.1707512 , 0.8292488 ],\n",
       "       [0.06636628, 0.9336337 ],\n",
       "       [0.12461422, 0.87538576],\n",
       "       [0.06642722, 0.93357277],\n",
       "       [0.64220256, 0.35779744],\n",
       "       [0.6846567 , 0.3153433 ],\n",
       "       [0.27253717, 0.7274628 ],\n",
       "       [0.6350751 , 0.36492488],\n",
       "       [0.06670711, 0.93329287],\n",
       "       [0.06664187, 0.9333582 ],\n",
       "       [0.71451634, 0.2854837 ],\n",
       "       [0.06635045, 0.9336496 ],\n",
       "       [0.7344538 , 0.2655462 ],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.4191138 , 0.5808862 ],\n",
       "       [0.71197426, 0.28802577],\n",
       "       [0.32949737, 0.67050254],\n",
       "       [0.7228905 , 0.2771095 ],\n",
       "       [0.7196528 , 0.28034723],\n",
       "       [0.7483863 , 0.25161365],\n",
       "       [0.6730106 , 0.32698938],\n",
       "       [0.63222814, 0.36777183],\n",
       "       [0.68556106, 0.31443894],\n",
       "       [0.7844902 , 0.21550982],\n",
       "       [0.71968764, 0.28031236],\n",
       "       [0.67484206, 0.32515797],\n",
       "       [0.66673285, 0.33326715],\n",
       "       [0.4379053 , 0.5620947 ],\n",
       "       [0.7959032 , 0.20409685],\n",
       "       [0.63033843, 0.3696616 ],\n",
       "       [0.06623676, 0.93376327],\n",
       "       [0.64490837, 0.35509166],\n",
       "       [0.67215955, 0.32784048],\n",
       "       [0.6538951 , 0.34610498],\n",
       "       [0.7553307 , 0.24466933],\n",
       "       [0.62526816, 0.37473184],\n",
       "       [0.7119283 , 0.28807166],\n",
       "       [0.627115  , 0.37288493],\n",
       "       [0.6807049 , 0.31929517],\n",
       "       [0.06629287, 0.9337071 ],\n",
       "       [0.6844051 , 0.3155949 ],\n",
       "       [0.82925534, 0.17074464],\n",
       "       [0.6236402 , 0.37635988],\n",
       "       [0.7063908 , 0.29360923],\n",
       "       [0.7197419 , 0.28025815],\n",
       "       [0.06620278, 0.93379724],\n",
       "       [0.43815458, 0.5618454 ],\n",
       "       [0.6538951 , 0.34610498],\n",
       "       [0.60497826, 0.39502174],\n",
       "       [0.17077395, 0.829226  ],\n",
       "       [0.60325825, 0.39674166],\n",
       "       [0.06671215, 0.93328786],\n",
       "       [0.7380539 , 0.26194608],\n",
       "       [0.7196534 , 0.28034657],\n",
       "       [0.60349584, 0.39650416],\n",
       "       [0.66061735, 0.33938256],\n",
       "       [0.7084454 , 0.29155457],\n",
       "       [0.06633691, 0.9336631 ],\n",
       "       [0.41327512, 0.5867249 ],\n",
       "       [0.7379595 , 0.2620405 ],\n",
       "       [0.67674273, 0.3232572 ],\n",
       "       [0.71836054, 0.28163943],\n",
       "       [0.6845201 , 0.31547987],\n",
       "       [0.7939753 , 0.20602474],\n",
       "       [0.06662227, 0.9333777 ],\n",
       "       [0.06660573, 0.9333942 ],\n",
       "       [0.6676417 , 0.33235827],\n",
       "       [0.0672624 , 0.9327376 ],\n",
       "       [0.06648368, 0.9335164 ],\n",
       "       [0.68165886, 0.3183411 ],\n",
       "       [0.6236834 , 0.37631664],\n",
       "       [0.06624213, 0.93375784],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.06622931, 0.93377066],\n",
       "       [0.7158974 , 0.28410262],\n",
       "       [0.06666065, 0.93333936],\n",
       "       [0.6996648 , 0.3003352 ],\n",
       "       [0.68925804, 0.31074196],\n",
       "       [0.7163602 , 0.28363985],\n",
       "       [0.69469416, 0.30530578],\n",
       "       [0.6271557 , 0.37284422],\n",
       "       [0.67426586, 0.3257341 ],\n",
       "       [0.7592396 , 0.2407603 ],\n",
       "       [0.3292313 , 0.67076874],\n",
       "       [0.7518748 , 0.2481252 ],\n",
       "       [0.08866332, 0.91133666],\n",
       "       [0.32974035, 0.67025965],\n",
       "       [0.6557692 , 0.3442308 ],\n",
       "       [0.5491759 , 0.45082414],\n",
       "       [0.16754554, 0.8324545 ],\n",
       "       [0.6268245 , 0.37317547],\n",
       "       [0.63493943, 0.36506057],\n",
       "       [0.06668611, 0.93331385],\n",
       "       [0.6633593 , 0.33664075],\n",
       "       [0.62474436, 0.37525564],\n",
       "       [0.26076314, 0.73923683],\n",
       "       [0.6595712 , 0.3404288 ],\n",
       "       [0.06635106, 0.93364894],\n",
       "       [0.7234544 , 0.27654558],\n",
       "       [0.74597824, 0.2540218 ],\n",
       "       [0.7380453 , 0.26195467],\n",
       "       [0.6206618 , 0.37933818],\n",
       "       [0.19745527, 0.8025448 ],\n",
       "       [0.67056865, 0.32943135],\n",
       "       [0.6523491 , 0.34765092],\n",
       "       [0.17070174, 0.82929826],\n",
       "       [0.667963  , 0.33203703],\n",
       "       [0.06629238, 0.93370765],\n",
       "       [0.7378739 , 0.2621261 ],\n",
       "       [0.06745078, 0.9325493 ],\n",
       "       [0.70800143, 0.2919985 ],\n",
       "       [0.06668564, 0.9333144 ],\n",
       "       [0.7080497 , 0.2919502 ],\n",
       "       [0.06647629, 0.9335238 ],\n",
       "       [0.22649501, 0.77350503],\n",
       "       [0.7158538 , 0.28414628],\n",
       "       [0.17076567, 0.8292343 ],\n",
       "       [0.77559143, 0.22440848],\n",
       "       [0.702997  , 0.29700288],\n",
       "       [0.61053056, 0.38946941],\n",
       "       [0.06625371, 0.93374634],\n",
       "       [0.71179396, 0.28820604],\n",
       "       [0.712269  , 0.28773096],\n",
       "       [0.6346082 , 0.3653918 ],\n",
       "       [0.7040064 , 0.2959936 ],\n",
       "       [0.69034153, 0.3096585 ],\n",
       "       [0.650303  , 0.349697  ],\n",
       "       [0.06672215, 0.9332778 ],\n",
       "       [0.06637587, 0.9336241 ],\n",
       "       [0.06649044, 0.9335095 ],\n",
       "       [0.06810284, 0.9318971 ],\n",
       "       [0.63511705, 0.36488298],\n",
       "       [0.7379017 , 0.26209828],\n",
       "       [0.747518  , 0.25248206],\n",
       "       [0.64252645, 0.35747358],\n",
       "       [0.0666563 , 0.93334377],\n",
       "       [0.7222184 , 0.27778158],\n",
       "       [0.06670711, 0.93329287],\n",
       "       [0.18395945, 0.8160406 ],\n",
       "       [0.06682128, 0.9331788 ],\n",
       "       [0.7039928 , 0.29600725],\n",
       "       [0.60469025, 0.3953097 ],\n",
       "       [0.7194213 , 0.28057864],\n",
       "       [0.7498741 , 0.25012589],\n",
       "       [0.7379595 , 0.26204047],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.7343163 , 0.2656837 ],\n",
       "       [0.06666961, 0.93333036],\n",
       "       [0.7080537 , 0.2919463 ],\n",
       "       [0.7658412 , 0.23415883],\n",
       "       [0.7080387 , 0.29196134],\n",
       "       [0.06680711, 0.9331929 ],\n",
       "       [0.274731  , 0.725269  ],\n",
       "       [0.6513127 , 0.34868726],\n",
       "       [0.7379003 , 0.2620997 ],\n",
       "       [0.62916493, 0.370835  ],\n",
       "       [0.7379595 , 0.2620405 ],\n",
       "       [0.5492326 , 0.4507674 ],\n",
       "       [0.6913235 , 0.30867648],\n",
       "       [0.6549543 , 0.34504566],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.06627361, 0.9337264 ],\n",
       "       [0.22324151, 0.7767585 ],\n",
       "       [0.6845208 , 0.3154792 ],\n",
       "       [0.06664511, 0.93335485],\n",
       "       [0.674647  , 0.32535297],\n",
       "       [0.7154244 , 0.2845756 ],\n",
       "       [0.68092984, 0.31907016],\n",
       "       [0.6519494 , 0.3480506 ],\n",
       "       [0.4371258 , 0.56287414],\n",
       "       [0.6284024 , 0.37159762],\n",
       "       [0.17076567, 0.8292343 ],\n",
       "       [0.11065611, 0.88934386],\n",
       "       [0.2846305 , 0.7153696 ],\n",
       "       [0.76218414, 0.23781589],\n",
       "       [0.73801094, 0.26198903],\n",
       "       [0.5970317 , 0.40296835],\n",
       "       [0.6845201 , 0.31547987],\n",
       "       [0.7378739 , 0.2621261 ],\n",
       "       [0.62617475, 0.37382516],\n",
       "       [0.18080837, 0.8191917 ],\n",
       "       [0.6845201 , 0.31547987],\n",
       "       [0.6675661 , 0.33243382],\n",
       "       [0.7618061 , 0.2381939 ],\n",
       "       [0.72714025, 0.27285972],\n",
       "       [0.06717908, 0.93282086],\n",
       "       [0.6845828 , 0.31541723],\n",
       "       [0.62769353, 0.37230653],\n",
       "       [0.7379074 , 0.26209262],\n",
       "       [0.7484321 , 0.25156793],\n",
       "       [0.6483166 , 0.35168335],\n",
       "       [0.726063  , 0.27393696],\n",
       "       [0.71954167, 0.2804583 ],\n",
       "       [0.17076567, 0.8292343 ],\n",
       "       [0.06633836, 0.93366164],\n",
       "       [0.5038431 , 0.49615684],\n",
       "       [0.62345165, 0.37654835],\n",
       "       [0.67178506, 0.328215  ],\n",
       "       [0.63451225, 0.36548772],\n",
       "       [0.69554013, 0.3044599 ],\n",
       "       [0.65767217, 0.3423278 ],\n",
       "       [0.7379552 , 0.2620448 ],\n",
       "       [0.31879732, 0.6812027 ],\n",
       "       [0.06646372, 0.9335363 ],\n",
       "       [0.1211561 , 0.8788439 ],\n",
       "       [0.6654877 , 0.3345123 ],\n",
       "       [0.6401913 , 0.35980868],\n",
       "       [0.7307729 , 0.2692271 ],\n",
       "       [0.64795625, 0.35204378],\n",
       "       [0.72716117, 0.27283886],\n",
       "       [0.6691579 , 0.33084208],\n",
       "       [0.66673285, 0.33326715],\n",
       "       [0.6353214 , 0.36467865],\n",
       "       [0.06624993, 0.9337501 ],\n",
       "       [0.71598864, 0.28401136],\n",
       "       [0.06672161, 0.93327844],\n",
       "       [0.65465903, 0.34534103],\n",
       "       [0.6763089 , 0.32369116],\n",
       "       [0.64769363, 0.3523064 ],\n",
       "       [0.06908748, 0.9309125 ],\n",
       "       [0.6437239 , 0.3562761 ],\n",
       "       [0.6845208 , 0.3154792 ],\n",
       "       [0.15795673, 0.8420432 ],\n",
       "       [0.73076576, 0.26923424],\n",
       "       [0.6292008 , 0.37079915],\n",
       "       [0.6888599 , 0.31114006],\n",
       "       [0.7247939 , 0.27520612],\n",
       "       [0.65994674, 0.34005332],\n",
       "       [0.6845201 , 0.31547987],\n",
       "       [0.63607717, 0.36392283],\n",
       "       [0.7484647 , 0.25153536],\n",
       "       [0.7808137 , 0.21918629],\n",
       "       [0.06589713, 0.93410283],\n",
       "       [0.74473435, 0.25526568],\n",
       "       [0.29090697, 0.7090931 ],\n",
       "       [0.66673285, 0.33326715],\n",
       "       [0.27583724, 0.72416276],\n",
       "       [0.65909123, 0.34090877],\n",
       "       [0.06681889, 0.93318117],\n",
       "       [0.06639755, 0.9336025 ],\n",
       "       [0.6633592 , 0.33664078],\n",
       "       [0.62459385, 0.37540612],\n",
       "       [0.7407157 , 0.25928435],\n",
       "       [0.37231547, 0.62768453],\n",
       "       [0.67353565, 0.32646438],\n",
       "       [0.06636043, 0.9336396 ],\n",
       "       [0.7379032 , 0.26209685],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.5963361 , 0.40366393],\n",
       "       [0.7430845 , 0.25691545],\n",
       "       [0.06742159, 0.9325784 ],\n",
       "       [0.06681889, 0.93318117],\n",
       "       [0.7306336 , 0.26936638],\n",
       "       [0.06630845, 0.93369156],\n",
       "       [0.68925804, 0.31074196],\n",
       "       [0.6842089 , 0.3157911 ],\n",
       "       [0.37900677, 0.62099326],\n",
       "       [0.06640038, 0.9335996 ],\n",
       "       [0.6484376 , 0.3515624 ],\n",
       "       [0.64763886, 0.35236114],\n",
       "       [0.06629913, 0.9337009 ],\n",
       "       [0.6739664 , 0.3260336 ],\n",
       "       [0.72925544, 0.2707446 ],\n",
       "       [0.06636903, 0.93363094],\n",
       "       [0.06627763, 0.9337223 ],\n",
       "       [0.5889956 , 0.4110044 ],\n",
       "       [0.6479348 , 0.3520653 ],\n",
       "       [0.68448496, 0.31551504],\n",
       "       [0.6807322 , 0.31926787],\n",
       "       [0.7122908 , 0.28770915],\n",
       "       [0.7005259 , 0.29947412],\n",
       "       [0.54332584, 0.45667407],\n",
       "       [0.4605506 , 0.53944933],\n",
       "       [0.6780053 , 0.32199472],\n",
       "       [0.06676679, 0.93323314],\n",
       "       [0.71970177, 0.28029823],\n",
       "       [0.76798916, 0.23201083],\n",
       "       [0.6800466 , 0.3199534 ],\n",
       "       [0.6645544 , 0.33544558],\n",
       "       [0.6097159 , 0.3902841 ],\n",
       "       [0.06639692, 0.9336031 ],\n",
       "       [0.6799429 , 0.3200571 ],\n",
       "       [0.73898447, 0.26101556],\n",
       "       [0.7519452 , 0.2480548 ],\n",
       "       [0.06623653, 0.9337635 ],\n",
       "       [0.6926087 , 0.30739132],\n",
       "       [0.06637856, 0.9336214 ],\n",
       "       [0.7119781 , 0.288022  ],\n",
       "       [0.7198485 , 0.28015143],\n",
       "       [0.06622437, 0.93377566],\n",
       "       [0.7094682 , 0.2905318 ],\n",
       "       [0.06629561, 0.93370444],\n",
       "       [0.5819478 , 0.4180522 ],\n",
       "       [0.6456544 , 0.35434556],\n",
       "       [0.6224592 , 0.3775408 ],\n",
       "       [0.6557218 , 0.3442782 ],\n",
       "       [0.6375318 , 0.36246818],\n",
       "       [0.17078017, 0.8292198 ],\n",
       "       [0.30496344, 0.69503653],\n",
       "       [0.17076567, 0.8292343 ],\n",
       "       [0.06634592, 0.93365407],\n",
       "       [0.5324917 , 0.46750832],\n",
       "       [0.7378739 , 0.2621261 ],\n",
       "       [0.06635682, 0.9336431 ],\n",
       "       [0.7704215 , 0.2295785 ],\n",
       "       [0.7378739 , 0.26212612],\n",
       "       [0.68446916, 0.3155308 ]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(x_test_honban)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:46.678158Z",
     "iopub.status.busy": "2020-10-27T04:10:46.677274Z",
     "iopub.status.idle": "2020-10-27T04:10:46.680342Z",
     "shell.execute_reply": "2020-10-27T04:10:46.679690Z"
    },
    "papermill": {
     "duration": 0.881803,
     "end_time": "2020-10-27T04:10:46.680476",
     "exception": false,
     "start_time": "2020-10-27T04:10:45.798673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_life=[]\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i][0]>y_pred[i][1]:\n",
    "        y_pred_life.append(0)\n",
    "    else:\n",
    "        y_pred_life.append(1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:48.475228Z",
     "iopub.status.busy": "2020-10-27T04:10:48.474243Z",
     "iopub.status.idle": "2020-10-27T04:10:48.481844Z",
     "shell.execute_reply": "2020-10-27T04:10:48.482756Z"
    },
    "papermill": {
     "duration": 0.933855,
     "end_time": "2020-10-27T04:10:48.482997",
     "exception": false,
     "start_time": "2020-10-27T04:10:47.549142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['PassengerId', 'Survived'],\n",
       "       ['892', '0'],\n",
       "       ['893', '0'],\n",
       "       ['894', '0'],\n",
       "       ['895', '0'],\n",
       "       ['896', '0'],\n",
       "       ['897', '0'],\n",
       "       ['898', '1'],\n",
       "       ['899', '0'],\n",
       "       ['900', '1'],\n",
       "       ['901', '0'],\n",
       "       ['902', '0'],\n",
       "       ['903', '0'],\n",
       "       ['904', '1'],\n",
       "       ['905', '0'],\n",
       "       ['906', '1'],\n",
       "       ['907', '1'],\n",
       "       ['908', '0'],\n",
       "       ['909', '0'],\n",
       "       ['910', '0'],\n",
       "       ['911', '1'],\n",
       "       ['912', '0'],\n",
       "       ['913', '0'],\n",
       "       ['914', '1'],\n",
       "       ['915', '0'],\n",
       "       ['916', '1'],\n",
       "       ['917', '0'],\n",
       "       ['918', '1'],\n",
       "       ['919', '0'],\n",
       "       ['920', '0'],\n",
       "       ['921', '0'],\n",
       "       ['922', '0'],\n",
       "       ['923', '0'],\n",
       "       ['924', '0'],\n",
       "       ['925', '0'],\n",
       "       ['926', '0'],\n",
       "       ['927', '0'],\n",
       "       ['928', '0'],\n",
       "       ['929', '1'],\n",
       "       ['930', '0'],\n",
       "       ['931', '0'],\n",
       "       ['932', '0'],\n",
       "       ['933', '0'],\n",
       "       ['934', '0'],\n",
       "       ['935', '1'],\n",
       "       ['936', '1'],\n",
       "       ['937', '0'],\n",
       "       ['938', '0'],\n",
       "       ['939', '0'],\n",
       "       ['940', '1'],\n",
       "       ['941', '0'],\n",
       "       ['942', '0'],\n",
       "       ['943', '0'],\n",
       "       ['944', '1'],\n",
       "       ['945', '1'],\n",
       "       ['946', '0'],\n",
       "       ['947', '0'],\n",
       "       ['948', '0'],\n",
       "       ['949', '0'],\n",
       "       ['950', '0'],\n",
       "       ['951', '1'],\n",
       "       ['952', '0'],\n",
       "       ['953', '0'],\n",
       "       ['954', '0'],\n",
       "       ['955', '1'],\n",
       "       ['956', '1'],\n",
       "       ['957', '1'],\n",
       "       ['958', '1'],\n",
       "       ['959', '0'],\n",
       "       ['960', '0'],\n",
       "       ['961', '1'],\n",
       "       ['962', '1'],\n",
       "       ['963', '0'],\n",
       "       ['964', '0'],\n",
       "       ['965', '0'],\n",
       "       ['966', '1'],\n",
       "       ['967', '0'],\n",
       "       ['968', '0'],\n",
       "       ['969', '1'],\n",
       "       ['970', '0'],\n",
       "       ['971', '1'],\n",
       "       ['972', '0'],\n",
       "       ['973', '0'],\n",
       "       ['974', '0'],\n",
       "       ['975', '0'],\n",
       "       ['976', '0'],\n",
       "       ['977', '0'],\n",
       "       ['978', '1'],\n",
       "       ['979', '1'],\n",
       "       ['980', '1'],\n",
       "       ['981', '1'],\n",
       "       ['982', '0'],\n",
       "       ['983', '0'],\n",
       "       ['984', '1'],\n",
       "       ['985', '0'],\n",
       "       ['986', '0'],\n",
       "       ['987', '0'],\n",
       "       ['988', '1'],\n",
       "       ['989', '0'],\n",
       "       ['990', '1'],\n",
       "       ['991', '0'],\n",
       "       ['992', '1'],\n",
       "       ['993', '0'],\n",
       "       ['994', '0'],\n",
       "       ['995', '0'],\n",
       "       ['996', '1'],\n",
       "       ['997', '0'],\n",
       "       ['998', '0'],\n",
       "       ['999', '0'],\n",
       "       ['1000', '0'],\n",
       "       ['1001', '0'],\n",
       "       ['1002', '0'],\n",
       "       ['1003', '1'],\n",
       "       ['1004', '1'],\n",
       "       ['1005', '1'],\n",
       "       ['1006', '1'],\n",
       "       ['1007', '0'],\n",
       "       ['1008', '0'],\n",
       "       ['1009', '1'],\n",
       "       ['1010', '0'],\n",
       "       ['1011', '1'],\n",
       "       ['1012', '1'],\n",
       "       ['1013', '0'],\n",
       "       ['1014', '1'],\n",
       "       ['1015', '0'],\n",
       "       ['1016', '0'],\n",
       "       ['1017', '1'],\n",
       "       ['1018', '0'],\n",
       "       ['1019', '1'],\n",
       "       ['1020', '0'],\n",
       "       ['1021', '0'],\n",
       "       ['1022', '0'],\n",
       "       ['1023', '0'],\n",
       "       ['1024', '0'],\n",
       "       ['1025', '0'],\n",
       "       ['1026', '0'],\n",
       "       ['1027', '0'],\n",
       "       ['1028', '0'],\n",
       "       ['1029', '0'],\n",
       "       ['1030', '1'],\n",
       "       ['1031', '0'],\n",
       "       ['1032', '0'],\n",
       "       ['1033', '1'],\n",
       "       ['1034', '0'],\n",
       "       ['1035', '0'],\n",
       "       ['1036', '0'],\n",
       "       ['1037', '0'],\n",
       "       ['1038', '0'],\n",
       "       ['1039', '0'],\n",
       "       ['1040', '0'],\n",
       "       ['1041', '0'],\n",
       "       ['1042', '1'],\n",
       "       ['1043', '0'],\n",
       "       ['1044', '0'],\n",
       "       ['1045', '0'],\n",
       "       ['1046', '0'],\n",
       "       ['1047', '0'],\n",
       "       ['1048', '1'],\n",
       "       ['1049', '1'],\n",
       "       ['1050', '0'],\n",
       "       ['1051', '0'],\n",
       "       ['1052', '1'],\n",
       "       ['1053', '0'],\n",
       "       ['1054', '1'],\n",
       "       ['1055', '0'],\n",
       "       ['1056', '0'],\n",
       "       ['1057', '0'],\n",
       "       ['1058', '0'],\n",
       "       ['1059', '0'],\n",
       "       ['1060', '1'],\n",
       "       ['1061', '1'],\n",
       "       ['1062', '0'],\n",
       "       ['1063', '0'],\n",
       "       ['1064', '0'],\n",
       "       ['1065', '0'],\n",
       "       ['1066', '0'],\n",
       "       ['1067', '1'],\n",
       "       ['1068', '1'],\n",
       "       ['1069', '0'],\n",
       "       ['1070', '1'],\n",
       "       ['1071', '1'],\n",
       "       ['1072', '0'],\n",
       "       ['1073', '0'],\n",
       "       ['1074', '1'],\n",
       "       ['1075', '0'],\n",
       "       ['1076', '1'],\n",
       "       ['1077', '0'],\n",
       "       ['1078', '1'],\n",
       "       ['1079', '0'],\n",
       "       ['1080', '0'],\n",
       "       ['1081', '0'],\n",
       "       ['1082', '0'],\n",
       "       ['1083', '0'],\n",
       "       ['1084', '0'],\n",
       "       ['1085', '0'],\n",
       "       ['1086', '1'],\n",
       "       ['1087', '0'],\n",
       "       ['1088', '1'],\n",
       "       ['1089', '1'],\n",
       "       ['1090', '0'],\n",
       "       ['1091', '0'],\n",
       "       ['1092', '1'],\n",
       "       ['1093', '0'],\n",
       "       ['1094', '0'],\n",
       "       ['1095', '1'],\n",
       "       ['1096', '0'],\n",
       "       ['1097', '0'],\n",
       "       ['1098', '1'],\n",
       "       ['1099', '0'],\n",
       "       ['1100', '1'],\n",
       "       ['1101', '0'],\n",
       "       ['1102', '0'],\n",
       "       ['1103', '0'],\n",
       "       ['1104', '0'],\n",
       "       ['1105', '1'],\n",
       "       ['1106', '0'],\n",
       "       ['1107', '0'],\n",
       "       ['1108', '1'],\n",
       "       ['1109', '0'],\n",
       "       ['1110', '1'],\n",
       "       ['1111', '0'],\n",
       "       ['1112', '1'],\n",
       "       ['1113', '0'],\n",
       "       ['1114', '1'],\n",
       "       ['1115', '0'],\n",
       "       ['1116', '1'],\n",
       "       ['1117', '1'],\n",
       "       ['1118', '0'],\n",
       "       ['1119', '1'],\n",
       "       ['1120', '0'],\n",
       "       ['1121', '0'],\n",
       "       ['1122', '0'],\n",
       "       ['1123', '1'],\n",
       "       ['1124', '0'],\n",
       "       ['1125', '0'],\n",
       "       ['1126', '0'],\n",
       "       ['1127', '0'],\n",
       "       ['1128', '0'],\n",
       "       ['1129', '0'],\n",
       "       ['1130', '1'],\n",
       "       ['1131', '1'],\n",
       "       ['1132', '1'],\n",
       "       ['1133', '1'],\n",
       "       ['1134', '0'],\n",
       "       ['1135', '0'],\n",
       "       ['1136', '0'],\n",
       "       ['1137', '0'],\n",
       "       ['1138', '1'],\n",
       "       ['1139', '0'],\n",
       "       ['1140', '1'],\n",
       "       ['1141', '1'],\n",
       "       ['1142', '1'],\n",
       "       ['1143', '0'],\n",
       "       ['1144', '0'],\n",
       "       ['1145', '0'],\n",
       "       ['1146', '0'],\n",
       "       ['1147', '0'],\n",
       "       ['1148', '0'],\n",
       "       ['1149', '0'],\n",
       "       ['1150', '1'],\n",
       "       ['1151', '0'],\n",
       "       ['1152', '0'],\n",
       "       ['1153', '0'],\n",
       "       ['1154', '1'],\n",
       "       ['1155', '1'],\n",
       "       ['1156', '0'],\n",
       "       ['1157', '0'],\n",
       "       ['1158', '0'],\n",
       "       ['1159', '0'],\n",
       "       ['1160', '0'],\n",
       "       ['1161', '0'],\n",
       "       ['1162', '0'],\n",
       "       ['1163', '0'],\n",
       "       ['1164', '1'],\n",
       "       ['1165', '1'],\n",
       "       ['1166', '0'],\n",
       "       ['1167', '1'],\n",
       "       ['1168', '0'],\n",
       "       ['1169', '0'],\n",
       "       ['1170', '0'],\n",
       "       ['1171', '0'],\n",
       "       ['1172', '1'],\n",
       "       ['1173', '0'],\n",
       "       ['1174', '1'],\n",
       "       ['1175', '1'],\n",
       "       ['1176', '1'],\n",
       "       ['1177', '0'],\n",
       "       ['1178', '0'],\n",
       "       ['1179', '0'],\n",
       "       ['1180', '0'],\n",
       "       ['1181', '0'],\n",
       "       ['1182', '0'],\n",
       "       ['1183', '1'],\n",
       "       ['1184', '0'],\n",
       "       ['1185', '0'],\n",
       "       ['1186', '0'],\n",
       "       ['1187', '0'],\n",
       "       ['1188', '1'],\n",
       "       ['1189', '0'],\n",
       "       ['1190', '0'],\n",
       "       ['1191', '0'],\n",
       "       ['1192', '0'],\n",
       "       ['1193', '0'],\n",
       "       ['1194', '0'],\n",
       "       ['1195', '0'],\n",
       "       ['1196', '1'],\n",
       "       ['1197', '1'],\n",
       "       ['1198', '0'],\n",
       "       ['1199', '0'],\n",
       "       ['1200', '0'],\n",
       "       ['1201', '0'],\n",
       "       ['1202', '0'],\n",
       "       ['1203', '0'],\n",
       "       ['1204', '0'],\n",
       "       ['1205', '1'],\n",
       "       ['1206', '1'],\n",
       "       ['1207', '1'],\n",
       "       ['1208', '0'],\n",
       "       ['1209', '0'],\n",
       "       ['1210', '0'],\n",
       "       ['1211', '0'],\n",
       "       ['1212', '0'],\n",
       "       ['1213', '0'],\n",
       "       ['1214', '0'],\n",
       "       ['1215', '0'],\n",
       "       ['1216', '1'],\n",
       "       ['1217', '0'],\n",
       "       ['1218', '1'],\n",
       "       ['1219', '0'],\n",
       "       ['1220', '0'],\n",
       "       ['1221', '0'],\n",
       "       ['1222', '1'],\n",
       "       ['1223', '0'],\n",
       "       ['1224', '0'],\n",
       "       ['1225', '1'],\n",
       "       ['1226', '0'],\n",
       "       ['1227', '0'],\n",
       "       ['1228', '0'],\n",
       "       ['1229', '0'],\n",
       "       ['1230', '0'],\n",
       "       ['1231', '0'],\n",
       "       ['1232', '0'],\n",
       "       ['1233', '0'],\n",
       "       ['1234', '0'],\n",
       "       ['1235', '1'],\n",
       "       ['1236', '0'],\n",
       "       ['1237', '1'],\n",
       "       ['1238', '0'],\n",
       "       ['1239', '1'],\n",
       "       ['1240', '0'],\n",
       "       ['1241', '1'],\n",
       "       ['1242', '1'],\n",
       "       ['1243', '0'],\n",
       "       ['1244', '0'],\n",
       "       ['1245', '0'],\n",
       "       ['1246', '1'],\n",
       "       ['1247', '0'],\n",
       "       ['1248', '1'],\n",
       "       ['1249', '0'],\n",
       "       ['1250', '0'],\n",
       "       ['1251', '0'],\n",
       "       ['1252', '0'],\n",
       "       ['1253', '1'],\n",
       "       ['1254', '1'],\n",
       "       ['1255', '0'],\n",
       "       ['1256', '1'],\n",
       "       ['1257', '0'],\n",
       "       ['1258', '0'],\n",
       "       ['1259', '1'],\n",
       "       ['1260', '1'],\n",
       "       ['1261', '0'],\n",
       "       ['1262', '0'],\n",
       "       ['1263', '1'],\n",
       "       ['1264', '0'],\n",
       "       ['1265', '0'],\n",
       "       ['1266', '1'],\n",
       "       ['1267', '1'],\n",
       "       ['1268', '0'],\n",
       "       ['1269', '0'],\n",
       "       ['1270', '0'],\n",
       "       ['1271', '0'],\n",
       "       ['1272', '0'],\n",
       "       ['1273', '0'],\n",
       "       ['1274', '0'],\n",
       "       ['1275', '1'],\n",
       "       ['1276', '0'],\n",
       "       ['1277', '1'],\n",
       "       ['1278', '0'],\n",
       "       ['1279', '0'],\n",
       "       ['1280', '0'],\n",
       "       ['1281', '0'],\n",
       "       ['1282', '0'],\n",
       "       ['1283', '1'],\n",
       "       ['1284', '0'],\n",
       "       ['1285', '0'],\n",
       "       ['1286', '0'],\n",
       "       ['1287', '1'],\n",
       "       ['1288', '0'],\n",
       "       ['1289', '1'],\n",
       "       ['1290', '0'],\n",
       "       ['1291', '0'],\n",
       "       ['1292', '1'],\n",
       "       ['1293', '0'],\n",
       "       ['1294', '1'],\n",
       "       ['1295', '0'],\n",
       "       ['1296', '0'],\n",
       "       ['1297', '0'],\n",
       "       ['1298', '0'],\n",
       "       ['1299', '0'],\n",
       "       ['1300', '1'],\n",
       "       ['1301', '1'],\n",
       "       ['1302', '1'],\n",
       "       ['1303', '1'],\n",
       "       ['1304', '0'],\n",
       "       ['1305', '0'],\n",
       "       ['1306', '1'],\n",
       "       ['1307', '0'],\n",
       "       ['1308', '0'],\n",
       "       ['1309', '0']], dtype='<U11')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_submit0 = ['PassengerId']\n",
    "my_submit1 = ['Survived']\n",
    "\n",
    "for i in range(0, len(y_pred)):\n",
    "    my_submit0.append(str(892+i))\n",
    "    my_submit1.append(str(y_pred_life[i]))\n",
    "\n",
    "    \n",
    "my_submit=[]\n",
    "\n",
    "my_submit.append(my_submit0)\n",
    "my_submit.append(my_submit1)\n",
    "\n",
    "my_submit2=np.transpose(my_submit)\n",
    "my_submit2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-10-27T04:10:50.216754Z",
     "iopub.status.busy": "2020-10-27T04:10:50.215765Z",
     "iopub.status.idle": "2020-10-27T04:10:50.219848Z",
     "shell.execute_reply": "2020-10-27T04:10:50.219186Z"
    },
    "papermill": {
     "duration": 0.872975,
     "end_time": "2020-10-27T04:10:50.220020",
     "exception": false,
     "start_time": "2020-10-27T04:10:49.347045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "my_submit3 = pd.DataFrame(my_submit2)\n",
    "my_submit3.to_csv('titanic_submission.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.861689,
     "end_time": "2020-10-27T04:10:51.949099",
     "exception": false,
     "start_time": "2020-10-27T04:10:51.087410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "duration": 96.344222,
   "end_time": "2020-10-27T04:10:52.946889",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-10-27T04:09:16.602667",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
